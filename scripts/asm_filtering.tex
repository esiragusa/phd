\chapter{Filtering methods}

This chapter presents filtering methods for approximate string matching.
I consider two classes of filtering methods: those based on \emph{seeds} and those based on \emph{$q$-grams}.
Filters of the former class partition the pattern into \emph{non-overlapping} factors called seeds, while filters in the latter class consider all \emph{overlapping} substrings of the pattern having length $q$, the so-called $q$-grams.
%Both classes of filters provide full-sensitive filtration schemes, solving the approximate string matching problem exactly.

These filters provide a trade-off between filtration speed and specificity.
Whenever the total time is dominated by verification time, a stronger filter yielding a lower number of candidate locations becomes appealing.
The total time improves, despite a moderate increase in filtration time, because of a significant reduction in verification time.
The former filters minimize filtration time but yield weak filtration, the latter provide a more involved but stronger filtration.
In practice, seeds filters work best at low error rates, while $q$-gram filters become competitive at higher error rates.
Thus we would adopt one or the other filtration method depending on the requested error rate.

The simple analysis of section~\ref{sec:filtering:exact} shows that filtration specificity is strongly correlated to the parameter $q$ being the seed or $q$-gram length.
Therefore the crux of designing stronger filters lies into increasing the seed or $q$-gram length while guaranteeing full-sensitivity.
To this intent, the following techniques have been proposed in literature:
\begin{inparaenum}[(i)]
\item gapped $q$-grams generalizing contiguous $q$-grams,
\item multiple gapped $q$-grams further generalizing gapped $q$-grams;
\item approximate seeds generalizing exact seeds,
%\item suffix filters further extending approximate seeds.
\end{inparaenum}

The idea of approximate seeds is that, to increase seed length, the pattern is factorized in less than $k+1$ non-overlapping seeds.
The pigeonhole lemma~\ref{lemma:exact-seeds} however tells that, by doing so, no seed will be guaranteed to be error-free.
Therefore, seeds must be searched approximately, but within a distance threshold smaller than the original threshold $k$.
We can search approximate seeds with backtracking techniques of section~\ref{sec:backtracking}.
%In a nutshell, instead of reducing an approximate search into smaller exact searches, we reduce it into smaller approximate searches.

Problems of exact and approximate seeds filters are that
\begin{inparaenum}[(i)]
\item it is not evident which factorization yields optimal filtration, and
\item they yield duplicate occurrences whenever errors are not distributed in the worst-case combination.
\end{inparaenum}
Suffix filters are based on tighter pigeonhole lemmas yielding stronger, less redundant, and more adaptive filtration using more efficiently the index.
The drawback is that the effort to implement them is slightly higher.


The idea of gapped $q$-grams is to lower the correlation between consecutive $q$-grams.
We have seen in the $q$-gram lemma~\ref{lemma:qgrams} that one error covers $q$ consecutive $q$-grams.
Thus, the occurrence of a $q$-gram is strongly correlated to the occurrence of its preceding and following $q$-grams.
Therefore, we introduce \emph{don't care positions} to skip characters at fixed positions inside all $q$-grams.
By doing so, a mismatch does not cover anymore all consecutive $q$-grams.
As less $q$-grams are now covered by mismatches, we can
\begin{inparaenum}[(i)]
\item increase the filtering threshold or
\item increase the number $q$ of considered characters,
\end{inparaenum}
in either cases preserving full-sensitivity.
Note that however, this concept poorly extends to edit distance, and the design of gapped $q$-grams is hard.

%TODO families.


%In the following of this chapter we first present (multiple) gapped $q$-grams and problems associated with their design.
%Then we move to more practical approximate seeds, which we will adopt later in chapter~\ref{chap:map-eng}.
%Finally we discuss suffix filters and their practicality.

%Overall, through this chapter:
%\begin{itemize}
%\item we present a framework for the design of (multiple) gapped $q$-grams consisting of efficient exact and approximate solutions;
%\item we provide generic parallel implementations of filters based on exact and approximate seeds;
%\item we evaluate these filtration schemes in practice.
%\end{itemize}

\section{Exact seeds}
\ref{sec:filtering:exact}

We start by considering the case of two arbitrary strings $x,y$ within edit distance $k$.
%If we partition \wlogs $y$ into $k+1$ non-overlapping seeds, then at least one seed will occur as a factor of $x$.
\begin{lemma}
\label{lemma:exact-seeds}
\citep{Baeza1999b}
Let $x,y$ be two strings \st $d_E(x,y) = k$.
%If $y=y^1 y^2 \dots y^{k+1}$ then $x=ay^ib$ for some $a, b$.
If we partition \wlogs $y$ into $k+1$ non-overlapping seeds, then at least one seed will occur as a factor of $x$.
\end{lemma}
%\begin{proof}
%We proceed by induction on $k$.
%For $k=0$, the string $y$ is partitioned into one factor, $y$ itself.
%The condition $d_E(x,y) = 0$ implies $x=y$, which is true for $a=\epsilon$ and $b=\epsilon$.
%We suppose the case $k=j-1$ to be true, thus since $d_E(x,y) = j-1$ and $y=y^1 y^2 \dots y^{j}$ then $x=ay^ib$ for some $a, b$.
%We consider the case $k=j$. The $j$-th error can be in
%\begin{inparaenum}[(i)]
%\item\label{lemma:exact-seeds:prefix} $y^1\dots y^{i-1}$,
%\item\label{lemma:exact-seeds:infix} $y^i$, or
%\item\label{lemma:exact-seeds:suffix} $y^{i+1}\dots y^{j}$.
%\end{inparaenum}
%In case~\ref{lemma:exact-seeds:prefix} or~\ref{lemma:exact-seeds:suffix}, $x=ay^ib$ clearly holds.
%In case~\ref{lemma:exact-seeds:infix}, if we partition $y^i$ in two factors $y^{i'}$ and $y^{i''}$, then either $x=ay^{i'}b'$ or $x={a'}y^{i''}b$.
%\end{proof}
It is immediate to see that any edit distance error can cover at most one seed, therefore at least one seed of $y$ will not be covered by any seed and occur as a factor of $x$.
Figure~\ref{fig:seeds-ext} shows an example.

\begin{figure}[h]
\begin{center}
\caption{Filtration with exact seeds.}
\label{fig:seeds-ext}
\input{figures/filtration_exact.tikz}
\end{center}
\end{figure}

Thus, we solve $k$-differences by partitioning the pattern into $k+1$ seeds and searching all seeds into the text, \eg with the help of a substring index.
As Lemma~\ref{lemma:exact-seeds} gives us a necessary but not sufficient condition, we must verify whether any candidate location induced by an occurrence of some seed corresponds to an approximate occurrence of the pattern in the text.
Thus, we verify any substring $s$ of the text of length $|s| \in [m - k, m + k]$ containing one seed of $p$.
Note how we are reducing one approximate search into many smaller exact searches.

How many verifications a seed produces?
Let us assume the text to be generated according to the uniform Bernoulli model.
The emission probability of any symbol in $\Sigma$ is $p = \frac{1}{\sigma}$ and under \iid assumptions the emission (and occurrence) probability of any word of length $q$ is simply
\begin{eqnarray}
\text{Pr}(H > 0) = \frac{1}{\sigma^q}
\end{eqnarray}
thus the expected number of occurrences of a seed of length $q$ in a text of length $n$ is
\begin{eqnarray}
E[H] = \sum_{i=1}^{n-q+1}{\text{Pr}(H > 0)} = \frac{n - q + 1}{\sigma^q} \leq \frac{n}{\sigma^q}.
\end{eqnarray}

Note how lemma~\ref{lemma:exact-seeds} requires us to partition the pattern into $k+1$ seeds but leaves us free to choose their length.
This leads to the question of which is an optimal pattern partitioning, \ie a partitioning that minimizes the expected number of verifications.
We fix\footnote{We ignore for simplicity that some seed could have length $\left \lceil \frac{m}{k+1} \right \rceil$.} the length of all seeds to be
\begin{eqnarray}
\label{eq:seed-len}
q=\left \lfloor \frac{m}{k+1} \right \rfloor
\end{eqnarray}
to minimize the expected number of occurrences of any seed.
Under these conditions, the expected number of verifications produced by our seed filter is
\begin{eqnarray}
E[V] = E[H] \cdot (k + 1) < \frac{n (k + 1)}{\sigma^q}
\end{eqnarray}

We now turn to the effect of the error rate on the runtime of the resulting $k$-differences algorithm.
For which error rate we expect the resulting algorithm to have sublinear runtime?
%\citeauthor{Gusfield1997} gives a rough estimate to this question.
If we use the classic $\Oh(m^2)$ DP algorithm of section~\ref{sub:introonline} to verify candidate locations, the expected runtime must be
\begin{eqnarray}
E[V] \cdot m^2 < cn
\end{eqnarray}
for some constant $c$.
By substituting $E[V]$ and solving for $q$, we obtain
\begin{eqnarray}
q > \log_{\sigma}{\frac{m^3}{c}}
\end{eqnarray}
and since we chose $q$ as a function of $m$ and $k$ in equation~\ref{eq:seed-len}, it follows that
\begin{eqnarray}
\epsilon = \frac{k}{m} < \frac{m}{\log_{\sigma}{m}}
\end{eqnarray}
is the error rate for which this $k$-differences algorithm has expected sublinear runtime.

Nonetheless, texts of practical interest like genomes and natural texts do not fit well the uniform Bernoulli model.
On those texts uniform seed length can lead to suboptimal filtration.
In section~\ref{sec:seeds-apx} we analyze the statistical properties of these texts and the effects of pattern partitioning.
Later, in order to obtain more robust filters, we generalize filtration with seeds to consider approximate seeds.


\section{Approximate seeds}
\label{sec:seeds-apx}

Approximate seeds have been proposed in \citep{Myers1994,Navarro2000} as a practical and effective generalization of exact seeds, yielding stronger filters both for $k$-mismatches and $k$-difference.
The key idea of approximate seeds is to reduce an approximate search into \emph{smaller} approximate searches, as opposed to exact seeds reducing an approximate search into smaller exact searches.

Again, we start by considering two arbitrary strings $x,y$ within edit distance $k$.
\begin{lemma}
\label{lemma:apx-seeds}
\citep{Myers1994,Navarro2000}
Let $x,y$ be two strings \st $d_E(x,y) = k$.
If we partition \wlogs $y$ into $s$ non-overlapping seeds \st $1 \leq s \leq k+1$, then at least one seed will occur as a factor of $x$ within distance $\lfloor k/s \rfloor$.
\end{lemma}
To prove full-sensitivity it suffices to see that, if none of the seeds occurs within its assigned distance, the total distance must be greater than $s \cdot \lfloor k/s \rfloor = k$.
Figure~\ref{fig:seeds-apx} illustrates.

In order to solve $k$-mismatches, we partition the pattern $p$ in non-overlapping seeds $p^1, p^2, \dots, p^s$. According to lemma~\ref{lemma:apx-seeds}, full-sensitivity is guaranteed if we search all seeds $p^i$ within a distance threshold of $\lfloor k/s \rfloor$.
Note that we are not obliged to assign the same distance threshold to all seeds.
Indeed, we can assign any arbitrary distance threshold $k_i$ to each seed $p^i$, as long as we satisfy the following inequality
\begin{equation}
s + \sum_{i=1}^{s}{k_i} > k.
\end{equation}
We usually tend to distribute evenly distance thresholds because seeds with the highest threshold dominate the overall filtration time.
Therefore, we assign to $(k \bmod{s}) + 1$ seeds distance $\lfloor k/s \rfloor$ and to the remaining seeds distance $\lfloor k/s \rfloor - 1$ \citep{Siragusa2013}.
Also note how we obtain lemma~\ref{lemma:exact-seeds} for exact seeds by posing $s=k+1$ and all $k_i = 0$.

\begin{figure}[h]
\begin{center}
\caption[Filtration with approximate seeds]{Filtration with approximate seeds.}
\label{fig:seeds-apx}
\input{figures/filtration_apx.tikz}
\end{center}
\end{figure}


\subsection{Parameterization}

With approximate seeds we are free to choose the number of seeds $s$ which gives us $q =\lfloor m/s \rfloor$, or vice versa, if we fix the minimum seed length $q$ then it must hold $s = \lfloor m/q \rfloor$.
The resulting filter is flexible, indeed by increasing $q$ filtration becomes more specific at the expense of a higher filtration time.
For $s=1$ we obtain the most specific filtration \ie we perform only backtracking and we do not even need to verify the reported locations, while for $s=k+1$ we obtain the fastest but weakest filtration.

In practice, it is not easy to find which filter parameterization yields an optimal filtration.
Both \citeauthor{Myers1994}, and \citeauthor{Navarro2000} carried out involved analysis to estimate the optimal parameters. \citeauthor{Navarro2000} find out that the optimal number of seeds $\Theta(\frac{m}{\log_{\sigma}{n}})$ yields an overall time complexity sublinear for an error rate $\epsilon < 1 - \frac{e}{\sqrt{\sigma}}$.
\citeauthor{Myers1994} reports an analogous sublinear time when $q=\Theta(\log_{\sigma}{n})$ is the seed length.
However, these results did not help us in our experiments.
The optimal partitioning depends on
\begin{inparaenum}[(i)]
\item the full-text index,
\item the verification algorithm,
\item the statistical properties of the text.
\end{inparaenum}
A difference of one from the optimal number of seeds can result in a runtime penalty of an order of magnitude.

\subsection{Redundancy}

Another practical problem of seeds is redundant filtration.
Whenever errors are not distributed according to a worst-case combination for lemma~\ref{lemma:exact-seeds} or \ref{lemma:apx-seeds}, more than one seed reports the same candidate location.
Consider the case of exact seeds: If two errors fall in some seed, then at least two seeds will occur exactly.

In practice, we can choose to avoid redundancy before or after verifying candidate locations.
After collecting all candidate locations for a pattern, we have to consider only the induced diagonal positions in the implicit DP matrix.
This requires locating and sorting all candidate locations for a pattern.
Alternatively, we can prefer to verify directly all candidate locations, \eg if the verification algorithm is fast and the number of redundant candidate locations is low.
Nonetheless, to avoid reporting duplicate occurrences, we have to consider redundant all occurrences either beginning or ending at the same position in the text.
This requires memorizing and sorting all occurrences of a pattern.

How many redundant error configurations\footnote{Here we consider the fraction of redundant error combinations and not the fraction of redundant candidate locations reported by the filter.} are produced by seeds filters?
For simplicity we consider exact seeds and combinations of exactly $k$ errors.
We have to cover all possible ways of distributing $k$ errors among $k+1$ seeds, that is $\binom{2k}{k}$ error combinations.
However, for a fixed seed, we cover all combinations where the seed itself contains no errors and all $k$ errors are distributed among the remaining $k$ seeds, \ie $\binom{2k-1}{k}$ error combinations.
Thus the fraction of error combinations covered by filtration with exact seeds over the minimal ones is
\begin{equation}
\frac{(k+1)\binom{2k-1}{k}}{\binom{2k}{k}} = \frac{k+1}{2}
\end{equation}
For instance, filtration with exact seeds covers three times more combinations than required when $k=5$.
With approximate seeds we partition the pattern in less seeds and thus we indirectly reduce filter redundancy.
%In the next section we see how suffix filters consider only minimal error combinations.

%\section{Suffix filters}

\section{Contiguous $q$-grams}

$q$-Gram filters are based on the so-called $q$-gram similarity measure $\tau_q : \Sigma^{*} \times \Sigma^{*} \rightarrow \N_0$, defined as the number of substrings of length $q$ common to two given strings.
The following lemma relates $q$-gram similarity to edit and Hamming distance.
It gives a lower bound on the $q$-gram similarity $\tau_q(x,y)$ of any two strings $x,y$ within edit distance $k$.
This means that $\tau_q(x,y) \geq k$ is a necessary but not sufficient condition for $d_E(x,y) \leq k$.
\begin{lemma}[The $q$-gram lemma] \citep{Jokinen1991}
\label{lemma:qgrams}
Let $x,y$ be two strings \st $d_E(x,y) = k$, and assume \wlogs $|x| \leq |y|$ and $|x| = m$. Then $x$ and $y$ have $q$-gram similarity $\tau_q(m,k) \geq m - q + 1 - kq$.
\end{lemma}
The first part of the threshold function $\tau$ counts the number of $q$-grams of $x$ (\ie $m - q + 1$), while the second part counts how many $q$-grams can be covered by $k$ errors ($kq$, \ie at most $q$ per error).
Figure~\ref{fig:qgrams-ext} illustrates.
Note how the threshold function $\tau$ depends only on the parameters $q,m,k$ and not on any specific $q$-gram.

\begin{figure}[h]
\begin{center}
\caption[Filtration with contiguous $q$-grams] {Filtration with contiguous $q$-grams.}
\label{fig:qgrams-ext}
\input{figures/filtration_qgrams.tikz}
\end{center}
\end{figure}

Lemma~\ref{lemma:qgrams} itself does not give us a direct solution to approximate string matching.
Indeed, it considers the edit distance between two arbitrary strings, while in approximate string matching the pattern can match any substring of the text.
More precisely, if the pattern approximately matches any substring $s$ of $t$, then in the case of $k$-mismatches $s$ must have length $m$; in the case of $k$-difference, the length of $s$ must be within $m - k$ and $m + k$.
The dot plot representation helps us to visualize this concept: $k$-mismatches occurrences cover one single diagonal of the dot plot, while $k$-difference occurrences are enclosed inside a parallelogram of side $2k+1$.

%How do we use lemma~\ref{lemma:qgrams} to solve approximate string matching?
Therefore, we can design an online filtration algorithm scanning the text and counting how many $q$-grams of the pattern fall into each parallelograms.
Only the parallelograms exceeding the threshold $\tau_q(m,k)$ have to be verified with an online method, \eg standard DP.
Alternatively, to speed up the filtration phase, we can count the $q$-grams with the help of a substring index.
%Overlapping parallelograms?

Which is the biggest $q$-gram length yielding lossless filtration given $m$ and $k$?
In order to satisfy lemma~\ref{lemma:qgrams}, the $q$-gram threshold must be greater than zero, \ie it must hold $\tau_q(m,k) \geq 1$.
Thus, by substituting $\tau$, we obtain $q \leq \left \lfloor \frac{m}{k+1} \right \rfloor$, analogously to equation~\ref{eq:seed-len} of seed filters.


\section{Gapped $q$-grams}

In section~\ref{sec:intro:filtering} we introduced the $q$-gram similarity measure as the number of substrings of length $q$ common to two given strings.
We now generalize this similarity measure to consider the number of common subsequences\footnote{A subsequence is a non-contiguous sequence of symbols of a given string.} of length $q$ whose symbols are taken from a fixed set $Q$ of positions.
%and related it to the edit and Hamming distance measures, with the intent of devising filtration criteria for approximate string matching.

\begin{definition}
We call $Q$-gram a finite sequence $Q$ of natural numbers starting with the unit element, \ie $Q \subset \N$ and $1 \in Q$.
We denote by $w(Q)$ the \emph{weight} of $Q$ as the cardinality of the set $|Q|$, and by $s(Q)$ the \emph{span} of $Q$ as the maximum element of the set $Q$.
\end{definition}

In literature, $Q$-grams are visualized as words over the alphabet $\{1,*\}$ or $\{\#,-\}$.
We adopt the former notation and represent the $Q$-gram by the word $w \in \{1,*\}^{s(Q)}$ such that $w_j=1$ iff $j \in Q$.
Figure~\ref{fig:qgram-shape} shows an example of $Q$-gram.

\begin{figure}[h]
\begin{center}
\caption[Filtration with gapped $q$-grams]{Filtration with gapped $q$-grams.}
\label{fig:qgrams-gapped}
\input{figures/filtration_qgrams_gapped.tikz}
\end{center}
\end{figure}

The first thing we remark is that, compared to contiguous $q$-grams, we obtain a higher threshold, as mismatches do not cover don't care positions.
The $q$-gram lemma (\ref{lemma:exact-qgrams}) does not provide us anymore with a tight threshold, but only with a lower bound.
Note that, as in the $q$-gram lemma, the threshold depends only on $Q$ and parameters $m,k$.
Indeed, the pattern of covered $q$-grams does not depend on the text or pattern sequences but only on their transcript, \ie on the position of the mismatches in the pattern.

%Don't care positions are immune only to mismatches but not to indels.

Gapped $q$-grams raise hard combinatorial questions. Given a gapped $q$-gram, 
\begin{inparaenum}[(i)]
\item \label{enum:qgram-non-detection} does it yield a full-sensitive filter for $k$-mismatches? If so, either
\item \label{enum:qgram-threshold} which is the maximum $q$-gram threshold $t$ that guarantees full-sensitivity? or 
\item \label{enum:qgram-error} which is the maximum error $k$ for which full-sensitivity is guaranteed?
If the answer to question~\ref{enum:qgram-nd} is negative and the filter is lossy,
\item \label{enum:qgram-fn} how many false negatives our filter discards?
Considering filtration efficiency,
\item \label{enum:qgram-fp} how many false positives our filter produces?
If we take the weight as a simplified criterion predicting filtration efficiency, 
\item \label{enum:qgram-weight} which is the maximum weight lossless shape?
\end{inparaenum}

Question~\ref{enum:qgram-threshold} has been first considered in \citep{Burkhardt2001,Kucherov2005},
the more general questions~\ref{enum:qgram-non-detection} and \ref{enum:qgram-weight} have been introduced in \citep{Nicolas2005}, while we consider here for the first time questions \ref{enum:qgram-error}-\ref{enum:qgram-fp}.
With the aim of elucidating these questions, we first introduce simple characteristic functions to formally define transcripts detected by gapped $q$-grams.
Afterwards, we recapitulate known results for questions \ref{enum:qgram-non-detection}-\ref{enum:qgram-weight} and give new exact and approximate solutions.

\subsection{Characteristic functions}

Consider an arbitrary transcript $\sigma$ as a $m$-dimensional vector over $\Bo$, where $|\sigma|_0$ indicates the Hamming distance of the transcript.
Let $\Bo^m_k \subset \Bo^m$ be the set containing all transcripts $\sigma$ such that $|\sigma|_0 = k$.

\begin{definition}
A $Q$-gram \emph{occurs} at position $i$ in a similarity $\sigma$ iff $\forall j \in Q$ $\sigma_{i+j}=1$.
Fixed a $Q$-gram threshold $t$, the $Q$-gram detects $\sigma$ iff it occurs at least $t$ times in $\sigma$.
\end{definition}

\subsubsection{Boolean functions}

Let $T_{Q}^{m}: \Bo^m \rightarrow \Bo$ denote a \emph{boolean function} such that $T_{Q}^{m}(\sigma)$ is true iff the $Q$-gram occurs at least one time in a similarity $\sigma$ of length $m$.
We define such boolean function as the disjunction
\begin{equation}
\label{eq:qgram-bool}
T_{Q}^{m}(\sigma) = \bigvee_{i=1}^{m-s(Q)+1} \bigwedge_{j \in Q} \sigma_{i+j}
\end{equation}
where each \emph{clause} of $T_{Q}^{m}$ represents a single possible occurrence of $Q$ in $\sigma$.
%The seed boolean function $T_{Q}^{m}$ describes the computation performed by the seed automaton $A_Q$ on all similarities of length $m$.
We define an analogous boolean function for a $Q$-gram family $F$ as the disjunction
\begin{equation}
\label{eq:family-bool}
T_{F}^{m}(\sigma) = \bigvee_{Q_i \in F} T_{Q_i}^{m}(\sigma)
\end{equation}
By definition, $T_{Q}^{m}$ and $T_{F}^{m}$ are \emph{monotone nondecreasing} boolean functions in \emph{disjunctive normal form} (\emph{DNF}).
Since all monotone boolean functions in DNF are minimal, $T_{Q}^{m}$ and $T_{F}^{m}$ are \emph{minimal}.

In general, $(Q,t)$ detects $\sigma$ iff $\sigma$ satisfies at least $t$ clauses of $T_{Q}^{m}$.

\subsubsection{Pseudo-boolean functions}

Let the function $t_{Q}^{m}: \Bo^m \rightarrow \N_0$ be the boolean function $T_{Q}^{m}$ acting on $\N_0$.
We defined such \emph{pseudo-boolean function} as
\begin{equation}
\label{eq:qgram-pseudo}
t_{Q}^{m}(\sigma) = \sum_{i=1}^{m-s(Q)+1} \prod_{j \in Q}\sigma_{i+j}
\end{equation}
Here $t_{Q}^{m}(\sigma)$ counts how many times a $Q$-gram occurs in a similarity $\sigma$ of length $m$.
It is useful to define the complementary function $\bar{t}_{Q}^{m}$, counting how many times a $Q$-gram does not occur in a similarity $\sigma$, as
\begin{equation}
\label{eq:qgram-pseudoneg}
\bar{t}_{Q}^{m}(\sigma) = m - s(Q) + 1 - t_{Q}^{m}(\sigma)
\end{equation}
Analogously, we define a pseudo-boolean function for a $Q$-gram family $F$
\begin{equation}
\label{eq:family-pseudo}
t_{F}^{m}(\sigma) = \sum_{Q_i \in F} t_{Q_i}^{m}(\sigma)
\end{equation}
along with its complementary function
\begin{equation}
\label{eq:family-pseudoneg}
\bar{t}_{F}^{m}(\sigma) = \sum_{Q_i \in F}{(m - s(Q_i) + 1)} - t_{F}^{m}(\sigma)
\end{equation}

The above functions expose important properties which will let us devise approximate solutions.
\emph{Nondecreasing monotonicity} of functions $t_{Q}^{m}$ and $t_{F}^{m}$ follow from nondecreasing monotonicity of their boolean counterparts $T_{Q}^{m}$ and $T_{F}^{m}$. Consequently $\bar{t}_{Q}^{m}$ and $\bar{t}_{F}^{m}$ are \emph{monotone nonincreasing}.
From definition~\ref{eq:supermodularity}, function $t_{Q}^{m}$ is \emph{supermodular}, thus it follows that $\bar{t}_{Q}^{m}$ is \emph{submodular}.
Since super and submodular functions are closed under non-negative linear combination, functions $t_{F}^{m}$ and $\bar{t}_{F}^{m}$ are respectively super and submodular.

\subsection{Full-sensitivity}

\textsc{Non Detection}~\citep{Nicolas2005}. Does a given gapped $q$-gram yield a full-sensitive filter for $k$-mismatches?

\subsubsection{Problem definition}

\paragraph{}
\begin{tabular}{rl}
{\bf Instance}	&	A $Q$-gram, two integers $m,k$ with $0 < k < m$. \\
{\bf Question}	&	Does it exist a similarity $\sigma \in \Bo^{m}_{k}$ such that $T_{Q}^{m}(\sigma)$ is false? \\
\end{tabular}
\\

\subsubsection{Hardness results}

\textsc{Non Detection} is \emph{strongly} NP-complete \citep{Nicolas2005}.
\citeauthor{Nicolas2005} introduce an intermediate problem, called \textsc{Soapy Set Cover}. They reduce \textsc{Exact Cover by 3-Sets} to \textsc{Soapy Set Cover} and \textsc{Soapy Set Cover} to \textsc{Non Detection}.
Strong NP-completeness implies that no \emph{FPTAS} nor any \emph{pseudo-polynomial} algorithm for it exist, under the assumption that $P \neq NP$.

\subsubsection{Our FPRAS solution}

%Recalling $Q$-gram pseudo-boolean functions \eqref{sec:seed_pbf}.

Describe FPRAS.


\subsection{Optimal threshold}

Which is the highest $Q$-gram threshold $t$ that guarantees full-sensitivity?
This problem has been introduced in \citep{Burkhardt2001}. %and generalized in \citep{Kucherov2005}.

\subsubsection{Problem definition}

\paragraph{}
\begin{tabular}{rl}
{\bf Instance}	&	A $Q$-gram, two integers $m,k$ such that $0 < k < m$.\\
{\bf Solution}	&	The largest integer $t^*$ such that \textsc{Non Detection} for $(Q,t^*),m,k$ answers \emph{no}.\\
\end{tabular}
\\

Recalling $Q$-gram pseudo-boolean functions \ref{eq:qgram-pseudo}, we can define the optimal threshold problem as the minimization of a supermodular function subject to linear constraints
\begin{equation}
\begin{array}{ll}
\min & t_{Q}^{m} (\sigma)			\\
w.r.t.								\\
& \sigma \in \Bo^m_k				\\
\end{array}
\end{equation}

\subsubsection{Exact DP solution}

Optimal threshold is fixed-parameter tractable (FPT) in the span of the $q$-gram shape.
\citeauthor{Burkhardt2001} give a DP algorithm computing the optimal threshold in time $O(m \cdot k \cdot 2^{s(Q)})$ \citep{Burkhardt2001}.
\citeauthor{Kucherov2005} give an extension for $Q$-gram families in \citep{Kucherov2005}.

All possible assignments, \ie $\Bo^s(Q)$, for the first clause $\bigwedge_{j \in Q}{\sigma_j}$ of the boolean function $T_{Q}^{m}$ are considered and all satisfying assignments for it, \ie $\phi(Q)$, are computed.
Clause $Q_2$ is considered next...

\subsubsection{Our exact ILP solution}

We reduce this problem to \emph{maximum coverage} \citep{NemhauserWolsey99} and solve it with the following ILP
\begin{equation}
\begin{array}{ll}
\max & |c|_1					\\
w.r.t.							\\
& \sigma \in \Bo^m_k			\\
& c \in \Bo^{m - s(Q) + 1}		\\
& \sigma_i \geq c_j				\\
\end{array}
\end{equation}
where variable $c_j$ indicates the truthfulness of the $j$-th clause in $T_{Q}^{m}$. Given the ILP solution $c^*$, we obtain the optimal threshold $t^* = |c^*|_1$.

\subsubsection{Our APX solution}

We reduce the complementary optimal threshold problem to the maximization of a submodular function subject to linear constraints
\begin{equation}
\begin{array}{ll}
\max & \bar{t}_{Q}^{m}(\sigma)		\\
w.r.t.								\\
& \sigma \in \bar{\Bo}^m_k			\\
\end{array}
\end{equation}
where the complementary optimal threshold is $\bar{t}^* = m - s(Q) + 1 - t^*$.

We compute an approximate solution via deepest descent.
Our greedy algorithm for complementary \textsc{Optimal Threshold} has an APX-ratio of $1 + 1/e$ \citep{NemhauserWolseyFisher78}.
The same \emph{absolute error} applies to \textsc{Optimal Threshold}.

\subsection{Maximum error}

Which is the maximum error $k^*$ for which full-sensitivity is guaranteed?

\subsubsection{Problem definition}

\paragraph{}
\begin{tabular}{rl}
{\bf Instance}	&	A $Q$-gram, an integer $m > 0$.\\
{\bf Solution}	&	The largest integer $k^*$ such that \textsc{Non Detection} for $Q,m,k^*$ answers \emph{no}.\\
\end{tabular}
\\

Recalling pseudo-boolean functions \ref{eq:qgram-pseudo}, we define our problem as the minimization of a linear function subject to submodular constraints
\begin{equation}
\begin{array}{ll}
\min & |\sigma|_1			\\
w.r.t.								\\
& \sigma \in \Bo^m					\\
& \bar{t}_{Q}^{m}(\sigma) \leq 0	\\
\end{array}
\end{equation}

\subsubsection{Our ILP solution}

We reduce our problem to \textsc{Minimum Set Cover} \citep{NemhauserWolsey99}, solve it with the following ILP
\begin{equation}
\begin{array}{ll}
\min & |\sigma|_1	\\
w.r.t.				\\
& \sigma \in \Bo^m	\\
& b \in \Bo^{m-s(Q)+1}\\
& A\sigma \geq b	\\
\end{array}
\end{equation}
where the value $A_{ij}$ of the coefficient matrix $A$ is defined as
\begin{equation}
A_{ij} = 
\left\{
	\begin{array}{ll}
		1  & \mbox{if } i-j+1 \in Q		\\
		0  & \mbox{if } i-j+1 \notin Q	\\
	\end{array}
\right.
\end{equation}
and find the maximum error for which full-sensitivity is guaranteed as $k^* = |\bar{\sigma}^*|_1$ given the solution $\sigma^*$ to the ILP.

Note that contiguous $q$-grams provide an interesting special case of this ILP.
If $A$ has the \emph{consecutive ones property}, it is \emph{totally unimodular}.
The \emph{polytope} defined by a totally unimodular coefficient matrix is \emph{integral}.
Hence the optimal solution of the relaxed LP is also the optimal solution of the original ILP.


\subsubsection{Our APX solution}

Again, we compute an approximate solution via deepest descent.
APX-ratio of $H_{w(Q)}$ \citep{NemhauserWolsey99}.


\subsection{Specificity}

How many false positives our filter produces?

\subsubsection{Problem definition}

\paragraph{}
\begin{tabular}{rl}
{\bf Instance}	&	A $Q$-gram, two integers $m,k$ such that $0 < k < m$.\\
{\bf Solution}	&	The number of false positives produced by the $Q$-gram.\\
\end{tabular}
\\

False positives are true points of the boolean function \ref{eq:qgram-bool} which have weight inferior to $m-k$ and satisfy more than $t$ clauses of $T_{Q^t}^{m}$.
Hence we define the function $\text{FP}_{k}^{m}$ counting the number of false positives of filter $(Q,t)$ in instance $(m,k)$ as
\begin{equation}
\text{FP}_{k}^{m}(Q,t) = \sum_{\sigma \in {\bar{\Bo}^{m}_{k}}} T_{Q,t}^{m}(\sigma)
\end{equation}

\subsubsection{Our FPRAS solution}

We reduce counting false positives to counting the number of true assignments to a boolean function in DNF.
The latter problem can be approximated via importance sampling.
\citeauthor{Vazirani01} introduces a \emph{RPTAS} approximating the number of true points of a DNF.
% Karp & Luby ??

%\subsection{Sensitivity and specificity}
%and \ref{enum:qgram-fn}.

\subsection{Optimal gapped $q$-grams}

Introduced in \citep{Nicolas2005}.

\subsubsection{Problem definition}

\paragraph{}
\begin{tabular}{rl}
{\bf Instance}	&	A finite set $S$ of similarities.\\
{\bf Solution}	&	A $Q$-gram that detects all similarities of $S$.\\
{\bf Measure}	&	The weight $w(Q)$ of the $Q$-gram.\\
\end{tabular}
\\

Given a set of similarities, find the $Q$-gram of maximum weight detecting all similarities.
This applies to the DNA Homology Search Framework as well.
%The MWLS is not the optimal seed for approximate string matching filtration nor for sequence homology filtration.
%On one hand the weight is just an estimator of sensibility regardless of threshold, on the other hand filtration speed decreases with increasing weight.

\subsubsection{Hardness and inapproximability results}

Nicolas et al. \citep{Nicolas2005} perform an approximation preserving reduction from \textsc{Maximum Independent Set}.
MWLS is NP-hard and APX-hard within $(|S|)^{0.25 - \epsilon}$ unless $P = NP$.
If $S = \Bo^{m}_{k}$, $|S| = \binom{m}{k}$.

\subsubsection{Branch-and-bound search}

Burkhardt et al. \citep{Burkhardt2001} bounding criterion. If $Q_1 \subseteq Q_2$, then $t_{Q_2}(m,k) \leq t_{Q_1}(m,k)$.
Such bounding criterion allows to discard parts of the search space which do not solve the considered $(m,k)$ instance.
%The search space of seed families is more dense than the search space of single seeds (i.e. almost all seed families solve a give Non Detection instance). Thus search space pruning would not be as effective.

% === Verification Methods ===

\section{Verification methods}
\label{sec:verification}
%\section{Myers' bit-vector algorithm}
\subsection{Banded Myers' bit-vector algorithm}
\subsection{Increased bit-parallelism using SIMD instructions}

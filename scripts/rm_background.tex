% =============================================================================

\chapter{Background}
\label{chr:background}

%In this chapter, I provide the background on read mapping.
%I first introduce HTS technologies from the standpoint of the bioinformatician who performs secondary analysis.
%I consider most popular sequencing instruments and mention aspects of the sequencing data that influence secondary analysis, \eg the paired-end and mate-pairs protocols, sequencing artefacts, and base qualities.
%Afterwards, I give insights on some properties of genomic sequences that make secondary analysis particularly difficult.
%I discuss how mappability helps to pinpoint genomic regions for which reference-guided assembly is hard.
%I present two paradigms for reference-guided assembly methods: best-mapping and all-mapping.
%Subsequently, I give an overview of most popular read mapping tools.
%I give key algorithmic ideas and relevant engineering solutions adopted by the various tools.

\section{High-throughput sequencing data}
\label{sec:background:sequencing}

%HTS technologies produce reads shorter than Sanger sequencing.
%Even worse, reads contain sequencing artefacts.
%Base qualities annotate single base accuracy.
%These properties of HTS data have to be taken into account for read mapping.

\subsection{Read sequences}

\subsubsection{Illumina}
Illumina / Solexa.

\subsubsection{Ion Torrent}
Life Technologies / Ion Torrent.

\subsubsection{Other technologies}

Roche / 454 Life Sciences.

SOLiD
%\emph{Applied Biosystems} (ABI) entered the market with its \emph{SOLiD} system, based on parallel sequencing by \emph{stepwise ligation}, reading two bases at a time with a florescent label in order to improve sequencing accuracy.

\subsection{Phred base quality scores}
\label{sec:background:hts:phred}

Base quality scores have been introduced by the base calling tool Phred \citep{Ewing1998, Ewing1998a} to assess sequencing quality of single bases in capillary reads.
Instead of discarding low-quality regions present in capillary reads, Phred output each base and annotates it with the probability that it has been wrongly called.
The tool encodes the probability $\epsilon_i$ of miscalling the $i$-th base in a read under the form of a base quality $Q_i$ in logarithmic space:
\begin{eqnarray}
\label{eq:phred}
Q_i = -10 \log_{10} \epsilon_i.
\end{eqnarray}
Since then, this method has been unanimously accepted.
All sequencing technologies complement DNA reads with base quality scores, in Phred-scale or similar.

% =============================================================================

\section{Data analysis paradigms}
\label{sec:paradigms}

The goal of secondary analysis is to reconstruct the original sequence of the donor genome.
The \emph{reference-guided} assembly plan assumes prior knowledge of a reference genome similar to the donor.
Reads are thus mapped (\ie aligned) to the reference genome \wrt a given scoring scheme and threshold.
The scoring scheme accounts for eventual genomic variation, as well as for any sequencing artefacts.
Under these assumptions, an alignment of optimal score for a read implies its \emph{original location} on the reference genome.
Conversely, no alignment within the score threshold implies too many sequencing errors, too much genetic variation, or sample contamination.
%A pile-up of the reads aligned at their mapping locations thus provides a consensus alignment of the donor genome.
A problem arises in presence of co-optimal or close sub-optimal alignments: the read cannot be mapped confidently to one single location.

The problem of confidently mapping high-throughput sequencing reads comes from the non-random nature of genomic sequences.
Genomes evolved through multiple types of duplication events, including whole-genome duplications \citep{Wolfe1997,Dehal2005} or large-scale segmental duplications in chromosomes \citep{Bailey2001,Samonte2002}, transposition of repetitive elements as short tandem repeats (microsatellites) \citep{Wang1994a,Wooster1994} and interspersed nuclear elements (LINE, SINE) \citep{Smit1996}, proliferation of repetitive structural elements such as telomeres and centromeres \citep{Meyne1990}.
As a result of these events, for instance, about 50~\% of the human genome is composed of repeats.

Repeats present in general technical challenges for all \emph{de novo} assembly and sequence alignment programs \citep{Treangen2011}.
Due to repetitive elements, a non-ignorable fraction of high-throughput sequencing reads cannot be mapped confidently.
In general, the shorter the reads, the higher the challenges due to repeats.
I quantify this phenomenon more precisely in section \ref{sec:mappability}.
Here I focus on analysis strategies to deal with \emph{multi-reads}, \ie reads that cannot be mapped confidently as they align equally well to multiple locations.

It is not evident how to treat \emph{multi-reads}.
According to \citeauthor{Treangen2011}, common strategies to deal with multi-reads are
\begin{inparaenum}[(i)]
\item to discard them all,
\item to randomly pick one best mapping location,
\item to consider all or up to $k$ best mapping locations within a given distance threshold.
\end{inparaenum}
A \emph{de facto} standard strategy, combining strategies (i) and (ii), emerged over the last years.
The read mapper randomly picks one best mapping location and complements it with its \emph{mapping quality}, \ie the probability of the mapping location being correct (see section~\ref{sec:paradigms:mapqual}).
Subsequently, downstream analysis tools apply a mapping quality score cutoff to discard reads not mapping confidently to any location.
The other popular strategy adopted by analysis tools is to consider all mapping locations within an edit distance threshold.
In this case, it is not clear whether downstream analysis tools consider equally all mapping locations regardless of their distance.

In the light of these facts, I define two broad paradigms for the secondary and tertiary analysis of HTS data: \emph{best-mapping} and \emph{all-mapping}.
The best-mapping paradigm considers a single mapping location per read along with its confidence, while the all-mapping paradigm considers a comprehensive set of mapping locations per read.
It goes without saying that read mapper and downstream analysis tools must agree on a common paradigm.
Thus these paradigms are valid not only for read mappers but also for any downstream analysis tool, \eg variant callers.
Read mapping and variant calling are indeed tightly coupled steps within reference-based HTS pipelines.

\subsection{Best-mapping}
As said, best-mapping methods rely on one single mapping location per read.
In order to maximize recall, best-mappers often adopt complex scoring schemes taking into account gaps and base quality values, and at the same time implement sophisticated heuristics to speed up the search.
Best-mappers annotate any mapping location with its mapping quality.
Subsequently, in order to maximize precision, variant calling tools decide whether to consider or discard reads not mapping confidently to any location.
The GATK~\citep{DePristo2011} and Samtools~\citep{Li2009a} are popular best-mapping tools to call small variants.
In section~\ref{sec:mappability}, I discuss how this paradigm systematically discards reads belonging some critical genomic regions, thus is limited to the analysis of \emph{high mappability} regions.

\subsubsection{Mapping quality score}
\label{sec:paradigms:mapqual}

Mapping quality has been introduced in the tool MAQ \citep{Li2008}.
The study considers short 30--40~bp reads, produced by early Illumina and ABI/SOLiD sequencing technologies, whose sequencing error rates were quite high.
Given the short lengths and high error rates, a significant fraction of such reads can be aligned to multiple mapping locations, even considering only co-optimal Hamming distance locations.

The argument of \citeauthor{Li2008} is that the Hamming distance is not an adequate scoring scheme to guess the correct mapping location of many reads.
The authors claim that \emph{``it is possible to act conservatively by discarding reads that map ambiguously at some level, but this leaves no information in the repetitive regions and it also discards data, reducing coverage in an uneven fashion, which may complicate the calculation of coverage.''}
Though, \citeauthor{Li2008} do not show in their study what is the effect of relying on mapping quality rather than on mapping uniqueness.
Since base callers output base call probabilities in Phred-scale along with the reads, \citeauthor{Li2008} propose a novel probabilistic scoring scheme called \emph{mapping quality}, encoding the probability that a read aligns correctly at a mapping location in the reference genome.

Fix the alphabet $\Sigma = \{$~A,~C,~G,~T~$\}$. Consider a known donor genome $g$ over $\Sigma$ and a read $r$ sequenced at location $l$ from the template $g_{l \dots l+|r|-1}$.
The base calling error $\epsilon_i$ from equation \ref{eq:phred} represents the probability $\epsilon_i$ of miscalling a base $r_i$ instead of calling its corresponding base $g_{l+i-1}$ in the donor genome.
The probability $p(r_i | g_{l+i-1})$ of observing the base $r_i$ given the donor genome base $g_{l+i-1}$, is:
\begin{eqnarray}
p(r_i | g_{l+i-1}) = \left\{
\begin{array}{ll}
1-\epsilon_i                  & \text{ if } g_{l+i-1} = r_i\\
\frac{\epsilon_i}{|\Sigma|-1} & \text{ if } g_{l+i-1} \in \Sigma \setminus \{r_i\}\\
\end{array}
\right.
\end{eqnarray}
and assuming \iid base calling errors, it follows that the probability $p(r | g, l)$ of observing the read $r$, given the donor genome template $g_{l \dots l+|r|-1}$, is:
\begin{eqnarray}
\label{eq:obsprob}
p(r | g, l) = \prod_{i=1}^{|r|}{p(r_i | g_{l+i-1})}.
\end{eqnarray}

By applying Bayes' theorem, \citeauthor{Li2008} derive the posterior probability $p(l|g,r)$, that location $l$ in the reference genome $g$ is the correct mapping location of read $r$.
Assuming uniform coverage, each location $l \in [1, |g| - |r| + 1]$ has equal probability of being the origin of a read in the donor genome, thus the prior probability $p(l)$ is simply:
\begin{eqnarray}
p(l) = \frac{1}{|g| - |r| + 1}
\end{eqnarray}
Therefore, recalling $p(r | g, l)$ from equation~\ref{eq:obsprob}, the posterior probability $p(l|g,r)$ equals the probability of the read $r$ originating at location $l$, normalized over all possible locations in the reference genome:
\begin{eqnarray}
\label{eq:mapprob}
p(l|g,r) = \frac{p(r|g,l)}{\sum_{i=1}^{|g| - |r| + 1}{p(r|g,i)}}
\end{eqnarray}
which in Phred-scale becomes:
\begin{eqnarray}
\label{eq:mapqual}
Q(l|g,r) = -10 \log_{10}[1 - p(l|g,r)].
\end{eqnarray}

Computing the exact mapping quality as in equation~\ref{eq:mapqual} requires aligning each read to all positions in the reference genome.
On the one hand, this computation is practically infeasible.
On the other hand, sub-optimal locations not close to the optimum one contribute very little to the sum in equation~\ref{eq:mapprob}.
Therefore, read mapping programs approximate equation~\ref{eq:mapprob} using only the mapping locations they repute relevant.

Mapping quality has been initially used in MAQ \citep{Li2008} and BWA \citep{Li2009} to maximize variant calling confidence by discarding reads whose best mapping location is below a given mapping quality threshold.
Since then, this method has been widely accepted.
Nowadays, mapping quality is computed by best-mappers and used by almost all variant calling tools \eg the Genome Analysis ToolKit (GATK) \citep{DePristo2011}.

Despite their wide adoption, some important objections can be raised against mapping quality scores.
First, this score is derived under the unlikely assumption of the reference genome being equal to the donor genome.
In other words, mapping quality considers only errors due to base miscalls and disregards genetic variation; thus the risk is to prefer mapping locations supported by known low base qualities rather than by true but unknown SNVs.
Second, mapping quality is nonetheless strongly correlated to mapping uniqueness, as discussed in section~\ref{sec:mappability}; it is easy to see that the probability of any location in equation~\ref{eq:mapprob} dilutes in presence of a large number of co-optimal or close sub-optimal mapping locations.
Third, mapping quality tends to become less relevant as base calls improve, due to advances of sequencing technologies, and thus degenerates into a shallow measure of uniqueness.

\subsection{All-mapping}
All-mapping analysis methods consider a comprehensive set of locations per read.
Almost all read mappers in this category adopt edit distance and report all mapping locations within an error threshold, absolute or relative \wrt to the length of the reads.
Variant calling algorithms based on all-mapping have the potential to detect a wider spectrum of genomic variation events than their best-mapping counterparts.
For instance, variant callers based on the all-mapping paradigm detect CNVs \citep{Alkan2009}, and SNVs in homologous regions \citep{Simola2011}.
 % transpositions~\citep{VariationHunter} ?
A practical challenge of all-mapping is represented by reporting and handling huge sets of mapping locations.

% -----------------------------------------------------------------------------

\section{Limits of high-throughput sequencing}
\label{sec:mappability}

A fraction of high-throughput sequencing reads cannot be mapped confidently due to repetitive elements.
Which regions of a model organism's genome cannot be resequenced confidently by a high-throughput sequencing technology?
And how accurate is downstream analysis on these low confidence regions?
Two recent studies \citep{Derrien2012, Lee2012} answer these questions.
Below, I report their key ideas and most relevant findings.

\subsection{Genome mappability}

\citeauthor{Derrien2012} define \emph{genome mappability} as a function of a genome for a fixed $q$-gram length, distance measure \ie the Hamming or edit distance, and distance threshold $k$.
Given a genomic sequence $g$, they define the $(q,k)$-frequency $F^q_k(l)$ of the $q$-gram $g_{l \dots l+q-1}$ at location $l$ in $g$ as the number of occurrences of the $q$-gram in $g$ and its reverse complement $\bar{g}$.
The $(q,k)$-mappability $M^q_k(l)$ is the inverse $(q,k)$-frequency, \ie $M^q_k(l) = {F^q_k(l)}^{-1}$ with $M^q_k : \N \rightarrow ]0,1]$.
Note that $M^q_k(l)$ can be seen as the prior probability that any read of length $q$ originating at location $l$ will be mapped correctly.
The values of $(q,k)$-frequency and mappability obviously vary with the distance threshold $k$. Nonetheless, under any distance measure, it hold that the $q$-gram at location $l$ is unique up to distance $k$ iff $M^q_k(l) = 1$ and repeated otherwise.

Unique mappability determines which fraction of a genome can be analyzed according to strategy (i) of \citep{Treangen2011} (\ie discarding non-unique reads, see section \ref{sec:paradigms}).
\citeauthor{Derrien2012} quantify the \emph{unique mappability} of whole human, mouse, fly, and worm genomes.
Mimicking typical Illumina read mapping setups, they consider $q$-grams of length 36, 50 and 75~bp, and Hamming distance 2.
They find out that about 30~\% of the whole human genome is not unique \wrt $(36,2)$-mappability.
At $(75,2)$-mappability, 17~\% of the human genome is not yet unique.
This last result is slightly optimistic, as typical mapping setups call for up to 3--4 edit distance errors in order to map a significant fraction of the reads.
Table \ref{tab:mappability} shows some results obtained from \citep{Derrien2012}.

%The uniqueome plays an important role in ChIP-seq experiments.
%It is common practice \citep{?} to rely on short (36~bp) reads and discard the non-unique ones.
%Not only a significant fraction of the sequencing data is thrown out.
%Worse than that, one ends up with holes in 30~\% of the genome.
%A ChIP-seq peak caller considering multi-reads calls up to 30~\% more peaks.
%Cite regions of of biological relevance \eg 5S rRNA, and clinical relevance \eg HLA-A.

\begin{table}[h]
\begin{center}
\caption[Mappability of model genomes]{Mappability of model genomes. Data obtained from \citep{Derrien2012}.}
\sffamily
\input{tables/table_mappability}
\label{tab:mappability}
\end{center}
\end{table}

To estimate single-base resequencing accuracy, \citeauthor{Derrien2012} consider the mappability of all possible $q$-grams spanning any single genomic location.
They define \emph{pileup mappability} $P^q_k$ at position $i$ as the average mappability of all $q$-grams spanning position $i$:
\begin{eqnarray}
P^q_k(i) = 1/q \sum_{j=i}^{i+1}{M^q_k(j)}.
\end{eqnarray}
\citeauthor{Derrien2012} find out in their own resequencing studies that \emph{``low pileup-mappability regions are more prone to show a high value of heterozygosity than those with high mappability''} \citep{Derrien2012}.
Ideally, variant calling tools call a locus as heterozygous whenever the consensus alignment column at that locus contains two distinct bases.
This situation tends to arise more frequently whenever the consensus alignment contains reads originating from similar yet distinct regions.

\subsection{Genome mappability score}

Genome mappability score (GMS) \citep{Lee2012}, analogously to pileup mappability, estimates single-locus resequencing accuracy for a specific sequencing technology.
Instead of considering the inverse $q$-gram frequency, \citeauthor{Lee2012} use mapping quality (see section~\ref{sec:paradigms:mapqual}) to estimate the probability that a read originating at a given position can be mapped correctly.
Subsequently, they derive the average mapping probability of any read spanning a location $l$ of a reference genome $g$ as:
%\footnote{Equation~3 in \citep{Lee2012} is not precise, please consider equation~\ref{eq:gms} instead.}
\begin{eqnarray}
\label{eq:gms}
p(l|g) = \sum_{r \in \mathcal{R}(l)}{\frac{p(l|g,r)}{|\mathcal{R}(l)|}}
\end{eqnarray}
which in Phred-scale becomes:
\begin{eqnarray}
Q(l|g) = \sum_{r \in \mathcal{R}(l)}{\frac{1 - 10^{-\frac{Q(l|g,r)}{10}}}{|\mathcal{R}(l)|}}.
\end{eqnarray}
Thus, fixed a genomic sequence $g$, they define the genome mappability score $\text{GMS}(l)$ in percentual value:
\begin{eqnarray}
\text{GMS}(l) = 100 \, Q(l|g)
\end{eqnarray}

\citeauthor{Lee2012} proceed as follow to compute GMS.
They first simulate reads from all genomic locations, having length and error profiles similar to those issue by actual sequencing technologies.
Subsequently, they compute mapping quality scores by mapping all simulated reads with the best-mapper BWA \citep{Li2009}.
Then, as just explained, they compute GMS at any location by averaging the quality scores.
Finally, they define \emph{low GMS} regions as those locations for which $\text{GMS}(l) \leq 10$ and \emph{high GMS} otherwise.
Table \ref{tab:gms} shows the performance of various sequencing technologies on the whole human genome (data obtained from \citep{Lee2012}).

\begin{table}[h]
\begin{center}
\caption[Human genome mappability score]{Human genome mappability score of various sequencing technologies. Data obtained from \citep{Lee2012}.}
\sffamily
\input{tables/table_gms}
\label{tab:gms}
\end{center}
\end{table}

\citeauthor{Lee2012} measure variant calling accuracy by GMS for the popular combination of best-mapping tools BWA and SAMtools \citep{Li2009a}.
They simulate an Illumina-like resequencing study and feed it to such analysis pipeline.
They find out that, at $30\,\times$ sequencing coverage, accuracy approaches 100~\% in high GMS regions, while it levels off to 25~\% in low GMS regions.
Their analysis \emph{``shows that most SNP detection errors are false negatives, and most of the missing variations are in regions with low GMS scores''} \citep{Lee2012}.
These are the limits of the \emph{de facto} standard best-mapping paradigm for the analysis of high-throughput sequencing data.

% =============================================================================


\section{Popular read mappers}

Following the boom of NGS technologies, recent bioinformatics research has produced dozens of tools to perform read mapping.
Two surveys \citep{Li2010, Fonseca2012} try to help bioinformaticians to extricate themselves from the jungle of read mapping tools.
The survey by \citeauthor{Li2010} first classifies read mapping algorithms by data structure: those based on hash tables and those based on suffix/prefix trees.
However, the adopted data structure is often an implementation detail, indeed most algorithms covered in the survey fit into both classes.
The survey primarily considers the application of SNP calling; in the considered setup, tools enumerating a comprehensive set of locations always lag behind those designed to report only one location per read.
The survey by \citeauthor{Fonseca2012} instead catalogs read mappers by the features exposed to the user.
It considers supported input--output formats, rate of errors and variation, number and type (\ie local or semi-global read alignments) of mapping locations reported.
After this exhaustive catalog, the survey concludes that the choice of a read mapper 
\emph{``involves application-specific requirements such as how well it works in conjunction with downstream analysis tools (\ie variant callers)''}.

Read mapping and variant calling are indeed tightly coupled steps within reference-based HTS analysis pipelines.
As explained above, secondary and tertiary analysis methods are based on one of the two following paradigms: best-mapping and all-mapping.
In the light of the above consideration, the most important feature of a read mapper is the number of mapping locations reported, followed by their type, while the other features are mostly of technical relevance.
Most read mappers are specifically designed to fit one paradigm, while others are versatile enough to work well in both cases.

The rest of this section presents most popular read mapping tools.
Among them, BWA \citep{Li2009}, Bowtie \citep{Langmead2009} and Bowtie~2\citep{Langmead2012}, and Soap \citep{Li2009b} are prominent tools designed for best-mapping, while SHRiMP~2 \citep{David2011}, mr(s)Fast \citep{Alkan2009,Hach2010}, RazerS \citep{Weese2009} and RazerS~3 \citep{Weese2012}, and Hobbes~2 \citep{Kim2014} are designed for all-mapping.
Grosso modo, most prominent best-mappers recursively enumerate substrings on a suffix/prefix tree of the reference genome via backtracking algorithms.
Backtracking alone is impractical as its time complexity grows exponentially with the number of errors considered, hence best-mappers apply heuristics to reduce and prioritize enumeration.
Conversely, all-mappers are based on filtering algorithms for approximate string matching.
They quickly determine, often with the help of an index, locations of the reference genome candidate to contain approximate occurrences, then verify them with conventional methods.
Their efficiency is bound to filtration specificity and thus deteriorates with increasing error rates and genome lengths.
Finally, the most recent tools GEM \citep{MarcoSola2012}, Masai \citep{Siragusa2013}, and Yara \citep{Siragusa2014}, fit both best and all-mapping paradigms.
They speed up best-mapping by stratifying mapping locations by edit distance and prioritizing filtration accordingly.
In addition to that, they also speed up all-mapping by means of more specific filters based on approximate seeds.
Table~\ref{tab:mappers} gives an overview of all these tools.

% -----------------------------------------------------------------------------

\subsection{Bowtie and Bowtie~2}
\label{background:mappers:bowtie}

Bowtie \citep{Langmead2009} is a mapper designed to have a small memory footprint and quickly report a few good mapping locations for early generation short Illumina and ABI/SOLiD reads.
The tool achieves the former goal by indexing the reference genome with an FM-index and the latter one by performing a greedy backtracking on it.
The greedy top-down traversal visits first the subtree yielding the least number of mismatches and stops after having found a candidate (not guaranteed to be optimal when $k>1$).
In addition, Bowtie speeds up backtracking by applying \emph{case pruning} \citep{Maekinen2010}, a simple application of the pigeonhole principle.
However, this technique is mostly suited for $k=1$ and requires the index of the forward and reverse reference genome.
Bowtie can be configured to search by strata, but the search time increases significantly while the traversal still misses a large fraction of the search space due to seeding heuristics.

Bowtie~2 \citep{Langmead2012} has been designed to quickly report a couple of mapping locations for longer Illumina, Ion Torrent and Roche/454 reads, usually having lengths in the range from 100~bp to 400~bp.
This tool uses an heuristic seed-and-extend approach, collecting seeds of fixed length, partially overlapping, and searching them exactly in the reference genome using an FM-index.
Bowtie~2 randomly chooses candidate locations, to avoid uncompressing large suffix array intervals and executing many DP instances.
The tool verifies candidate locations using a striped vectorial dynamic programming algorithm by \cite{Farrar2007}, implemented using SIMD instructions.
Bowtie~2 can be configured to report semi-global or local alignments, scored using a tunable affine scoring scheme.
%However, its heuristic filtration method, independent of the scoring scheme, makes it hard to believe what it promises.

% -----------------------------------------------------------------------------

\subsection{BWA}
\label{background:mappers:bwa}

BWA \citep{Li2009} is designed to map Illumina reads and report a few best semi-global alignments.
The program backtracks the FM-index of the reference genome with a \emph{greedy breadth-first search}.
The tool ranks nodes to be visited by edit distance score: the best node is popped from a priority queue and visited, its children are then inserted again in the queue.
The traversal considers indels using a more involved 9-fold recursion.
\citeauthor{Li2009} speed up backtracking by adopting a more stringent pruning strategy \citep{Maekinen2010} that nonetheless takes some preprocessing time and requires the index of the reverse reference genome.
BWA performs paired-end alignments by trying to anchor both paired-end reads and verifying the corresponding mate, within an estimated insert size, using the classic DP-based Smith-Waterman algorithm.
Consequently, the program in paired-end mode aligns reads at a slower rate than in single-end mode.
The program is not fully multi-threaded, therefore it scales poorly on modern multi-core machines.

%BWA-SW \citep{Li2010a} is designed to map Roche/454 reads, which have an average length of 400~bp.
%It is an heuristic version of BWT-SW, designed to report a few good local alignments.
%This variant of BWA adopts a double indexing strategy: it indexes all substrings of one read in a DAWG.
%It performs Smith-Waterman of all read substrings directly on the FM-index, by backtracking as soon as no viable alignment can be obtained.
%As in the first BWA, the traversal proceeds in a greedy fashion.
%In addition, BWA-SW implements some seeding heuristics to limit backtracking and jump in the reference genome to verify candidate locations whenever this becomes favorable.

% -----------------------------------------------------------------------------

\subsection{Soap}
\label{background:mappers:soap}

Soap~2 \citep{Li2009b} has been designed to produce a very quick but shallow mapping of short Illumina reads, up to 2 mismatches and without indels.
The tool performs backtracking using the so-called bi-directional (or 2-way) BWT \citep{Belazzougui2013}.
Soap~2 supports paired-end mapping but at a slower alignment rate, it lacks native output in the \emph{de-facto} standard SAM format, and it is not open source.

% -----------------------------------------------------------------------------

\subsection{SHRiMP~2}
\label{background:mappers:shrimp}

The \emph{SHort Read Mapping Program} (SHRiMP~2) \citep{David2011} is designed for mapping sensitivity and achieves high accuracy at the expense of speed.
SHRiMP~2 indices the reference genome using multiple gapped $q$-grams.
At query time, it projects each read to identify candidate mapping locations, which are verified with the Smith–Waterman algorithm \citep{Smith1981}.
The SHRiMP~2 project has been recently discontinued.

% -----------------------------------------------------------------------------

\subsection{RazerS and RazerS~3}
\label{background:mappers:razers}

RazerS \citep{Weese2009} has been designed to report all mapping locations within a fixed Hamming or edit distance error rate.
It is based on a full-sensitive $q$-gram counting filtration method (see section \ref{sec:filtering:qgrams-ext}) combined with the edit distance verification algorithm by Myers \citep{Myers1999}.
On demand, the tool throttles filtration to be more specific at the expense of a controlled loss rate.
Stronger filtration reduces the number of candidate locations and improves the overall speed of the program.
All in all, the SWIFT filter is very slow while not highly specific.

RazerS~3 \citep{Weese2012} is a faster version featuring shared-memory parallelism, a banded version of Myers' algorithm, and a quicker filtration method based on exact seeds (see section \ref{sec:filtering:exact}).
Such filtration method however turns out to be very weak on mammal genomes.
Because of this fact, RazerS~3 is one-two orders of magnitude slower than Bowtie~2 and BWA on such datasets.

All RazerS versions index the reads and scan the reference genome.
One positive aspect of this strategy is that no preprocessing of the reference genome is required.
However, other mapping strategies beyond all-mapping, \eg mapping by strata, cannot be efficiently implemented.
Moreover, these programs exhibit an high memory footprint as they remember the mapping locations of all input reads until the whole reference genome has been scanned.

% -----------------------------------------------------------------------------

\subsection{mrFast and mrsFast}
\label{background:mappers:mrsfast}

The tools mrsFast \citep{Hach2010} and mrFast \citep{Ahmadi2012} are designed to map Illumina reads.
They report all mapping locations within a fixed absolute number errors, respectively under the edit and Hamming distance.
Similarly to RazerS~3, these two programs implement full-sensitive filtration using exact seeds (section \ref{sec:filtering:exact}).
Their peculiarity is a cache-oblivious strategy to mitigate the high cost of verifying clusters of candidate locations.
In addition, mrsFast computes the edit distance between one read and one mapping location in the reference genome with an antidiagonal-wise vectorial dynamic programming algorithm, implemented using SIMD instructions.
These tools perform only all-mapping, produce files of impractical size and lack multi-threading support.

% -----------------------------------------------------------------------------

\subsection{Hobbes~2}
\label{background:mappers:hobbes}

Hobbes~2 \citep{Kim2014} is designed to identify all read mapping locations within a fixed Hamming or edit distance threshold.
In order to improve filtering efficiency, the tool employs a novel technique of so-called \emph{prefix $q$-grams} that enriches the reference genome $q$-gram index.
However, this technique does not guarantee full-sensitivity.

% -----------------------------------------------------------------------------

\subsection{GEM}
\label{background:mappers:gem}

The GEM mapper \citep{MarcoSola2012} is a flexible read aligner for Illumina and Ion Torrent reads.
It is  and can be configured either as an all-mapper, as a best/unique-mapper, or to search by strata.
GEM implements full-sensitive filtration with approximate seeds (see section \ref{sec:seeds-apx}).
The program indexes the reference genome with an FM-index, tries to find an optimal filtration scheme per read, and verifies candidate locations using Myers' algorithm \cite{Myers1999}.
GEM maps paired-reads in two ways: either it maps both ends independently and then combines them, or maps one end and then verifies the other end using an online method.
Unfortunately, the tool is not open source and provides obscure parameterization.

% -----------------------------------------------------------------------------

%\subsection{Masai and Yara}

% -----------------------------------------------------------------------------

\begin{landscape}
\begin{table}[h]
  \center
  \caption[Overview of popular read mappers]{Overview of popular read mappers.}
  \sffamily
%  \resizebox{1.0\textwidth}{!}
%  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_mappers}
%  }
\label{tab:mappers}
\end{table}
\end{landscape}


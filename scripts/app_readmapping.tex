% =============================================================================

\chapter{Background}

Next generation sequencing is a terrific technology.
A wealth of applications have been developed on top of it.
Data analysis pipelines for variant calling and structural variation discovery from DNA-seq, mRNA transcripts abundance estimation and novel non-coding RNA discovery from RNA-seq, transcription factor binding-sites prediction from ChIP-seq.
All these applications rely on a common prerequisite step: mapping NGS reads to a known reference genome.

Read mapping is a critical step in all NGS data analysis pipelines.
NGS reads produced by all current technologies contain sequencing errors, in form of single miscalled bases or stretches of oligonucleotides.
Moreover, the donor genome from which reads have been sequenced contains small genomic variations (SNVs, Indels) in addition to CNV, inversions and translocations.
After all, spotting genomic variation is one reason for which we resequence genomes.
Thus, when mapping a read to a reference genome, it is not sufficient to consider the loci where the reads map exactly; it is necessary to consider any loci of relevant sequence similarity, being possible origins of the sequenced reads.

\section{Sequencing technologies}

\subsection{Illumina}
Illumina / Solexa.

\subsection{Ion Torrent}
Life Technologies / Ion Torrent.

\subsection{Other technologies}

\subsubsection{454 Life Sciences}
Roche / 454 Life Sciences.

\subsubsection{SOLiD}
ABI / SOLiD.

\section{Sequencing protocols and applications}

\subsection{DNA-seq}
\subsection{RNA-seq}
\subsection{ChIP-seq}

\section{Sequencing quality}

%\subsection{Phred base quality values}

Phred base quality values have been introduced in \citep{Ewing1998, Ewing1998b} to assess the quality of sequencing single bases in capillary reads.
Instead of directly discarding low-quality regions present in capillary reads, Phred calls each base and annotates it with a quality score encoding the probability that it has been wrongly called.
As this method has been widely accepted, base callers annotate reads issue of all sequencing technologies with Phred base quality scores.

To formally define Phred base quality values, let us fix the alphabet $\Sigma = \{$~A,~C,~G,~T~$\}$, and consider a known donor genome $g$ over $\Sigma$ and a read $r$ sequenced at location $l$ from the template $g_{l \dots l+|r|-1}$.
We define the base calling error $\epsilon_i$ at position $i$ in the read $r$, as the probability $\epsilon_i$ of miscalling a base $r_i$ instead of calling its corresponding base $g_{l+i-1}$ in the donor genome.
Therefore, we define the Phred base quality $Q_i$ at position $i$ as:
\begin{eqnarray}
Q_i = -10 \log_{10} \epsilon_i.
\end{eqnarray}

Given the above, the probability $p(r_i | g_{l+i-1})$ of calling the base $r_i$ in the read $r$, given the donor genome base $g_{l+i-1}$, is:
\begin{eqnarray}
p(r_i | g_{l+i-1}) = \left\{
\begin{array}{ll}
1-\epsilon_i                  & \text{ if } g_{l+i-1} = r_i\\
\frac{\epsilon_i}{|\Sigma|-1} & \text{ if } g_{l+i-1} \in \Sigma \setminus \{r_i\}\\
\end{array}
\right.
\end{eqnarray}
and assuming \iid base calling errors, it follows that the probability $p(r | g, l)$ of observing the read $r$, given the donor genome template $g_{l \dots l+|r|-1}$, is:
\begin{eqnarray}
\label{eq:phred}
p(r | g, l) = \prod_{i=1}^{|r|}{p(r_i | g_{l+i-1})}
\end{eqnarray}

% =============================================================================

\section{Mappability}
\label{sec:mappability}

Genome resequencing is a non-trivial task.

The difficulty of unambiguously finding the correct mapping location of next-generation sequencing reads comes from the non-random nature of genomes.
Genomes evolved through multiple types of duplication events, including
\begin{inparaenum}[(i)]
\item whole-genome duplications \citep{?} or large-scale segmental duplications in chromosomes \citep{?},
\item transposition of repetitive elements as short tandem repeats (microsatellites) and interspersed nuclear elements (LINE, SINE) \citep{?},
\item proliferation of repetitive structural elements such as telomeres and centromeres \citep{?}.
\end{inparaenum}
As a result of these events, about 50~\% of the human genome is composed of repeats.

An analysis of the $k$-mer spectra of the genomes of some model organisms shows how genomes are statistically different from texts randomly generated according to uniform bernoulli models.

Repeats present in general technical challenges for all \emph{de novo} assembly and sequence alignment programs \citep{Lee2012}.
In the case of short reads mapping, the first evident effect of the heavy tail in the $k$-mer distribution of reference genomes is the dramatic loss of specificity in certain regions, which increases the computational cost of programs based on filtration methods.
But the most subtle challenge lies in the interpretation of these results: it is not evident how to consider reads mapping to multiple locations.

Common strategies to deal with multi-reads are
\begin{inparaenum}[(i)]
\item to discard them all,
\item to randomly pick one best mapping location,
\item to consider all or up to $k$ best mapping locations within a given distance threshold
\end{inparaenum}
\citep{Treangen2011}.

A practical challenge is represented by reporting and handling the resulting datasets of mapping locations, which can have a size up to two orders of magnitude bigger compared to the corresponding input read sets.

Genome mappability can bias NGS analysis more than we might think at a first glance.
Two recent studies \citep{Derrien2012, Lee2012} show which is the bias of mappability.


% -----------------------------------------------------------------------------

\subsection{Genome mappability}

We now give a definition of genome mappability analogous to \citep{Derrien2012}.
Let fix a $q$-gram length, a distance measure as the Hamming or edit distance, and a distance threshold $k$.
Given a genomic sequence $g$, we define the $(q,k)$-frequency $F^q_k(l)$ of the $q$-gram $g_{l \dots l+q-1}$ at location $l$ in $g$ as the number of occurrences of the $q$-gram in $g$ and its reverse complement $\bar{g}$.
We define the $(q,k)$-mappability $M^q_k(l)$ as the inverse $(q,k)$-frequency, \ie $M^q_k(l) = {F^q_k(l)}^{-1}$ with $M^q_k : \N \rightarrow ]0,1]$.
Note that $M^q_k(l)$ can be seen as the prior probability that any read of length $q$ originating at location $l$ will be mapped correctly.
The values of $(q,k)$-frequency and mappability obviously vary with the distance threshold $k$. Nonetheless, under any distance measure, it hold that the $q$-gram at location $l$ is unique up to distance $k$ iff $M^q_k(l) = 1$ and repeated otherwise.

Which is the minimum $q$-gram length from which we expect $(q,k)$-mappability to be $1$ for the genomes of model organisms?
Let consider the simple case of exact $(q,0)$-mappability.
By assuming a genomic sequence of length $n$ as being randomly generated under the uniform bernoulli model, the emission probability of any nucleotide is $p=\frac{1}{4}$ and, under \iid assumptions, the emission probability of any $q$-gram is $p_q=\frac{1}{4^q}$.
It follows that the expected value of $(q,0)$-frequency is $E[F^q_0] \simeq \frac{2n}{4^q}$.
Thus, for $E[F^q_0] \leq 1$ it must hold:
\begin{eqnarray}
2n \leq 4^q\\
\log{2n} \leq \log{4^q}\\
q \geq log_{4}{2n}
\end{eqnarray}
Thus, we would expect any $q$-gram of length $\log_{4}2n$ to occur about once in a genomic sequence of length $n$.
Sticking to these assumption, in the human genome ($n \approx 3\cdot10^9$) almost all 17-mers would be unique, on fly ($n \approx 1.2\cdot10^8$) all 15-mers, on worm ($n \approx 4.2\cdot10^7$) all 13-mers.
However, the $q$-gram distribution of model genomes does not fit the uniform bernoulli distribution.
In \citep{?} the $k$-mers distribution can be approximated by a double Pareto log-normal distribution, \ie a distribution with a heavy tail.
This is a result of the evolution of genomes being driven by gene duplications, retrotransposons \citep{?}.


Consequently, we would expect 36~bp reads produced by early Illumina sequencers to induce an almost perfect mappability.
However, reads have to be mapped approximately to the reference genome.
The expected number of approximate occurrences of a $k$-mer is higher than the exact one.
Thus the above estimate is a lower bound.

\subsubsection{Uniqueome}

\citeauthor{Derrien2012} quantified the whole genome unique mappability for human, mouse, fly, and worm.
At a $(36,2)$ mapping, about 30~\% of the human genome is not uniquely mappable.
Unique mappability rises to 83~\% by increasing the read length to 75~bp; however to map a significant fraction of the reads, we should consider 3--4 edit distance errors.

\begin{table}[h]
\begin{center}
\caption[Mappability of model genomes]{Mappability of model genomes. Data extrapolated from \citep{Derrien2012}.}
\sffamily
\input{tables/table_mappability}
\end{center}
\end{table}

The uniqueome plays an important role in ChIP-seq experiments.
It is common practice \citep{?} to rely on short (36~bp) reads and discard the non-unique ones.
Not only a significant fraction of the sequencing data is thrown out.
Worse than that, we end up with holes in 30~\% of the genome.
A ChIP-seq peak caller considering multi-reads calls up to 30~\% more peaks.

Cite regions of clinical relevance, \eg HLA-A.
Cite regions of biological relevance, \eg 5S rRNA.

\subsubsection{Paired-end mappability}

\subsubsection{Pileup mappability}

If we focus our attention to the resequencing accuracy at a single locus, we have to consider the mappability of all the possible reads spanning that given locus.
Pileup mappability \citep{Derrien2012} at position $i$ is the average mappability of all reads spanning position $i$.

$M_p(i) = 1/q \sum_{j=i}^{i+1}{M(j)}$


\subsection{Mapping quality score}
\label{sub:mapqual}

Mapping quality has been introduced in \citep{Li2008}.
The study considers short reads of length ranging from 30~bp to 40~bp, produced by early Illumina/Solexa and ABI/SOLiD sequencing technologies, whose sequencing error rates were quite high.
Given the short lengths and high error rates, a significant fraction of such reads can be aligned to multiple mapping locations, even considering only co-optimal Hamming distance locations.

The key point is that the Hamming distance is not an adequate scoring scheme to guess the correct mapping location of many reads.
The authors claim\footnote{\citeauthor{Li2008} do not show in their study what is the effect of relying on mapping quality rather than on mapping uniqueness.} that:
\begin{quote}It is possible to act conservatively by discarding reads that map ambiguously at some level, but this leaves no information in the repetitive regions and it also discards data, reducing coverage in an uneven fashion, which may complicate the calculation of coverage.\end{quote}
Since base callers output base call probabilities in Phred-scale along with the reads, \citeauthor{Li2008} propose a novel probabilistic scoring scheme called mapping quality, giving the probability that a given read has been aligned correctly at a given mapping location in the reference genome.

By applying Bayes' theorem, we can derive the posterior probability $p(l|g,r)$, that location $l$ in the reference genome $g$ is the correct mapping location of read $r$.
Assuming uniform coverage, each location $l \in [1, |g| - |r| + 1]$ has equal probability of being the origin of a read in the donor genome, thus the prior probability $p(l)$ is simply:
\begin{eqnarray}
p(l) = \frac{1}{|g| - |r| + 1}
\end{eqnarray}
Therefore, recalling $p(r | g, l)$ from equation~\ref{eq:phred}, the posterior probability $p(l|g,r)$ equals the probability of the read $r$ originating at location $l$ normalized over all possible locations in the reference genome:
\begin{eqnarray}
\label{eq:mapprob}
p(l|g,r) = \frac{p(r|g,l)}{\sum_{i=1}^{|g| - |r| + 1}{p(r|g,i)}}
\end{eqnarray}
which in Phred-scale becomes:
\begin{eqnarray}
\label{eq:mapqual}
Q(l|g,r) = -10 \log_{10}[1 - p(l|g,r)]
\end{eqnarray}

Computing the exact mapping quality as in equation~\ref{eq:mapqual} requires aligning each read to all positions in the reference genome.
On one hand, this computation would not be practical, indeed the vast majority of a reference genome is discarded when mapping reads by means of filtering and fully-indexed methods.
On the other hand, the contribution of discarded locations to the sum in equation~\ref{eq:mapprob} can be neglected.
Therefore, equation~\ref{eq:mapprob} is approximated using only relevant mapping locations found by the read mapper.

Mapping quality has been initially used in \citep{Li2008} and \citep{Li2009} to maximize variant calling confidence by discarding reads whose best mapping location is below a given mapping quality threshold.
This measure has been widely accepted: nowadays it is computed by most popular read mappers and used by almost all variant calling pipelines \eg the Genome Analysis ToolKit (GATK) \citep{DePristo2011}.

Nonetheless, some important objections can be moved against mapping quality.
First, the mapping quality score is derived under the unlikely assumption of the reference genome being equal to the donor genome.
In other words, mapping quality considers only errors due to base miscalls and disregards genetic variation; thus the risk is to prefer mapping locations supported by known low base qualities rather than by true but unknown SNVs.
Second, mapping quality is nonetheless strongly correlated to mapping uniqueness, as discussed in section~\ref{sec:mappability}; it is easy to see that the mapping probability in equation~\ref{eq:mapprob} is diluted in presence of a large number of co-optimal mapping locations.
Third, mapping quality tends to become less relevant as base calls improve, due to advances of sequencing technologies, and thus degenerates in a shallow measure of uniqueness.

\subsection{Genome mappability score}

Genome mappability score (GMS) \citep{Lee2012} is analogous to pileup mappability.
Instead of considering the inverse mapping frequency $(q,k)$-mappability, we can interpret mapping quality (see subsection~\ref{sub:mapqual}) as the probability that a read originating at a given position can be mapped correctly. %which is effectively a probabilistic mappability measure,
Therefore, we consider the average mapping probability of any read spanning a location $l$ of a reference genome $g$\footnote{Equation~3 in \citep{Lee2012} is not precise, please refer to our equation~\ref{eq:gms}.}:
\begin{eqnarray}
\label{eq:gms}
p(l|g) = \sum_{r \in \mathcal{R}(l)}{\frac{p(l|g,r)}{|\mathcal{R}(l)|}}
\end{eqnarray}
which in Phread-scale becomes:
\begin{eqnarray}
Q(l|g) = \sum_{r \in \mathcal{R}(l)}{\frac{1 - 10^{-\frac{Q(l|g,r)}{10}}}{|\mathcal{R}(l)|}}
\end{eqnarray}
and thus, fixed a genomic sequence $g$, we define the genome mappability score $\text{GMS}(l)$ as its percentual value:
\begin{eqnarray}
\text{GMS}(l) = 100 Q(l|g)
\end{eqnarray}

\citeauthor{Lee2012} simulate reads having length and error profiles similar to those issue by actual sequencing technologies, define low GMS regions as those locations for which $\text{GMS}(l) \leq 10$, and measure the percentage of such locations in the human genome.

\begin{table}[h]
\begin{center}
\caption[Human genome mappability score]{Human genome mappability score of various sequencing technologies. Data extrapolated from \citep{Lee2012}.}
\sffamily
\input{tables/table_gms}
\end{center}
\end{table}

% =============================================================================


\section{Popular read mappers}

Following the boom of NGS technologies, recent bioinformatics research has produced dozens of tools to perform read mapping.
Two surveys \citep{Li2010, Fonseca2012} try to help bioinformaticians to extricate themselves from the jungle of read mapping tools.
The survey by \citeauthor{Li2010} first classifies read mapping algorithms by data structure: those based on hash tables and those based on suffix/prefix trees.
However, the adopted data structure is often an implementation detail, indeed most algorithms covered in the survey fit into both classes.
The survey primarily considers the application of SNP calling; in the considered setup, tools enumerating a comprehensive set of locations always lag behind those designed to report only one location per read.
The survey by \citeauthor{Fonseca2012} catalogs read mappers by the features exposed to the user.
It considers supported input--output formats, rate of errors and variation, number and type (\ie local or semi-global read alignments) of mapping locations reported.
After this exhaustive catalog, the survey concludes that the choice of a read mapper 
\emph{involves application-specific requirements such as how well it works in conjunction with downstream analysis tools (\ie variant callers)}.

Read mapping and variant calling are indeed tightly coupled steps of secondary analysis within reference-based NGS pipelines.
Secondary analysis methods are based on one of the two following paradigms: best-mapping and all-mapping.
The best-mapping paradigm considers a single mapping location per read, while the all-mapping paradigm considers a comprehensive set of mapping locations per read.
In the light of the above consideration, the most important feature of a read mapper is the number of mapping locations reported, followed by their type, while the other features are mostly of technical relevance.
Most read mappers are specifically designed to fit one paradigm, while others are versatile enough to work well in both cases.

As said, best-mapping methods rely on one single mapping location per read.
In order to maximize recall, best-mappers often adopt complex scoring schemes taking into account gaps and base quality values, and at the same time implement sophisticate heuristics to speed up the search.
Best-mappers should always complement any mapping location with its mapping quality (see section~\ref{sec:mapping:quality}), denoting the probability of the mapping location being correct, \ie the probability that it corresponds to the read's original location.
Subsequently, in order to maximize precision, variant calling tools decide wether to consider or discard reads not mapping confidently to any location.
The GATK~\citep{gatk} and Samtools~\citep{samtools} are popular best-mapping tools to call small variants.
Clearly, these methods are limited to the analysis of high mappability regions, as they systematically discard reads sequenced from low mappability regions (see section~\ref{sec:mapping:mappability}).

All-mapping analysis methods consider a comprehensive set of locations per read.
Almost all read mappers in this category adopt edit distance, the simplest scoring scheme, and report all mapping locations within an error threshold, absolute or relative \wrt to the length of the reads.
Variant callers in this category implement calling algorithms able to detect a wider spectrum of genomic variation, like CNVs~\citep{mrCaNaVaR}, as well as long indels~\citep{SPLITREAD}, transpositions~\citep{VariationHunter}, and SNVs in low-mappability regions~\citep{Sniper}.

The rest of this section presents most popular read mapping tools.
Among them, BWA~\citep{bwa,bwa-sw}, Bowtie~\citep{bowtie,bowtie2} and Soap~\citep{soap} are prominent tools designed for best-mapping, while mr(s)Fast~\citep{mrfast,mrsfast}, RazerS~\citep{razers,razers3}, SHRiMP~\citep{razers,razers3} are designed for best-mapping.
Grosso modo, most prominent best-mappers recursively enumerate substrings on a suffix/prefix tree of the reference genome via backtracking algorithms.
Backtracking alone is impractical as its time complexity grows exponentially with the number of errors considered, hence best-mappers apply heuristics to reduce and prioritize enumeration.
Conversely, all-mappers are based on filtering algorithms for approximate string matching.
They quickly determine, often with the help of an index, locations of the reference genome candidate to contain approximate occurrences, then verify them with conventional methods.
Their efficiency is bound to filtration specificity and thus deteriorates with increasing error rates and genome lengths.
Finally, the most recent tools GEM~\citep{gem}, Masai~\citep{Siragusa2013}, and Yara, fit both best and all-mapping paradigms.
They speed up best-mapping by stratifying mapping locations by edit distance and prioritizing filtration accordingly.
In addition to that, they also speed up all-mapping by means of more specific filters based on backtracking.

%In best-mapping, the task of a read mapper is to guess original mapping locations of reads.
%Fixed a similarity scoring scheme that confidently models this problem, the optimal alignment under this scoring scheme correspond to the most likely explanation and induces a locus being the origin of the read.
%The simplest scoring scheme is the edit distance; more involved scoring schemes take into account base quality values, score gaps using affine cost functions, or allow to trim for free a prefix or a suffix of the read.

%The above definition does not consider two problems: what if there are many co-optimal candidates, and what if the correct solution corresponds to a sub-optimal candidate.
%The former problem is exacerbated by genome mappability.
%One would expect such situations to arise very rarely, but instead it is a relevant problem.
%The latter problem arises whenever our model is not adequate to explain the difference between a read and its genomic origin.
%For instance, an evolutionary event producing an indel of length $l$ might be considered as a unit, whether edit distance would consider it as $l$ independent events.
%Under the edit distance, an alignment with less than $l$ independent point mutations would be considered more likely than an alignment containing only one indel of length $l$.

% -----------------------------------------------------------------------------

\subsection{Bowtie}

Bowtie \citep{Bowtie} is a mapper designed to have a small memory footprint and quickly report a few good mapping locations for early generation Illumina/Solexa and ABI/SOLiD short reads of length up to 50~bp.
It achieves the former goal by indexing the reference genome with an FM-index and the latter goal by performing a greedy depth-first traversal on it.

The greedy depth-first traversal visits first the subtree yielding the least number of mismatches and stops after having found a candidate (not guaranteed to be optimal when $k>1$).
In addition, Bowtie speeds up backtracking by applying case pruning, a simple application of the pigeonhole principle.
However this technique is mostly suited for $k=1$ and requires the index of the forward and reverse text.

Bowtie can be configured to search by strata, however the search time increases significantly while the traversal still misses a large fraction of the search space due to seeding heuristics.
Main practical drawbacks of the tool are too many cryptic options.

Bowtie~2 \citep{Bowtie2} has been designed to quickly report a couple of mapping locations for recent Illumina/Solexa, Ion Torrent and Roche/454 reads, usually having lengths in the range from 100~bp to 400~bp.

This tool uses an heuristic seed-and-extend approach, collecting seeds of fixed length, partially overlapping, and searching them exactly in the reference genome using an FM-index.
Candidate locations to verify are chosen randomly, to avoid uncompressing large CSA intervals and executing many DP instances.
Each mapping location is verified using a striped vectorial dynamic programming algorithm, implemented using SIMD instructions, previously introduced by \citep{Farrar2007} and extended to compute end-to-end alignments.

Bowtie~2 can be configured to report end-to-end or local alignments, scored using a tunable affine scoring scheme.
For this reason, it is believed to be good at reporting alignments containing indels.
However, its completely heuristic filtration method, independent of the scoring scheme, makes it hard to believe what it promises.

% -----------------------------------------------------------------------------

\subsection{BWA}

BWA-backtrack \citep{BWA} is designed to map Illumina/Solexa reads up to 100~bp and report a few best end-to-end alignments.
The program performs a greedy breadth-first search on an FM-index of the reference genome.
Nodes to be visited are ranked by edit distance score: the best node is popped from a priority queue and visited, its children are then inserted again in the queue.
The traversal considers indels using a more involved 9-fold recursion.
Backtracking is sped up by adopting a more stringent pruning strategy that nonetheless takes some preprocessing time and requires the index of the reverse reference genome.

BWA performs paired-end alignments by trying to anchor both paired-end reads and verifying the corresponding mate, within an estimated insert size, using the classic DP-based Smith-Waterman algorithm.
Consequently, the program in paired-end mode aligns reads at a slower rate than in single-end mode.
The program is not fully multi-threaded, therefore BWA scales poorly on modern multi-core machines.

BWA-SW \citep{BWA-SW} is designed to map Roche/454 reads, which have an average length of 400~bp.
It is an heuristic version of BWT-SW, designed to report a few good local alignments.

This version of BWA adopts a double indexing strategy: it indexes all substrings of one read in a DAWG.
It performs Smith-Waterman of all read substrings directly on the FM-index, by backtracking as soon as no viable alignment can be obtained.
As in BWA-backtrack, the traversal proceeds in a greedy fashion.
In addition, BWA-SW implements some seeding heuristics to limit backtracking and jump in the reference genome to verify candidate locations whenever this becomes favorable.

This version of BWA does not support paired-end reads, presumably because it was meant for Roche/454 reads.

% -----------------------------------------------------------------------------

\subsection{Soap}

Soap~2 \citep{Soap2} is very similar to Bowtie: it has been designed to produce a very quick but shallow mapping of Illumina/Solexa reads up to 75~bp with no more than 2 mismatches and no indels.
However, its underlying algorithm is based on the so-called bi-directional (or 2-way) BWT.
The tool support paired-end mapping but at a slower alignment rate.
Practical drawbacks are the lack of native output in the de-facto standard SAM format and is closed source.
Soap~3 \citep{Soap3} is algorithmically similar to Soap~2 but targets only NVIDIA CUDA accelerators.

% -----------------------------------------------------------------------------

\subsection{SHRiMP}

SHRiMP~2 TODO.

% -----------------------------------------------------------------------------

\subsection{RazerS}

RazerS \citep{Weese2009} has been designed to report all mapping locations within a fixed hamming or edit distance error rate.
It is based on a full-sensitive $q$-gram filtration method (SWIFT semi-global) combined with the Myers edit distance verification algorithm.
On demand, the SWIFT filter can be configured to become lossy within a fixed loss rate.
The lossy filter becomes more stringent and produces a lower number of candidates to verify, thus improving the overall speed of the program.
All in all, the SWIFT filter is very slow while not highly specific.

RazerS~3 \citep{RazerS3} is a faster version featuring shared-memory parallelism, a faster banded-Myers verification algorithm, and a faster filtration scheme based on exact seeds that however turns out to be very weak on mammal genomes.
Because of this, RazerS~3 is one-two orders of magnitude slower than Bowtie~2 and BWA-backtrack on mammal genomes.

All RazerS versions index the reads and scan the reference genome.
One positive aspect of this strategy is that no preprocessing of the reference genome is required.
However, other mapping strategies beyond all-mapping, \eg mapping by strata, cannot be efficiently implemented.
Moreover, the program exhibit an high memory footprint as it must remember the mapping locations of all input reads until the whole reference genome has been scanned.

% -----------------------------------------------------------------------------

\subsection{mr(s)Fast}

The tools mrFast \citep{Ahmadi2011} and mrsFast \citep{Hach2010} are designed to report all mapping locations within a fixed absolute number errors, respectively under the hamming and edit distance, given Illumina/Solexa reads of length ranging from 50~bp to 125~bp.
Similarly to RazerS~3, they are based on a full-sensitive filtration method using exact seeds, which turns out to be very weak on mammal genomes.

The peculiarity of their underlying method is a cache-oblivious strategy to mitigate the high cost of verifying clusters of candidate locations.
In addition, mrsFast computes the edit distance between one read and one mapping location in the reference genome with an antidiagonal-wise vectorial dynamic programming algorithm, implemented using SIMD instructions.

These tools are as slow as RazerS~3 and appealing for nothing more than all-mapping.
They lack multi-threading support and exhibit various bugs.
Furthermore, they only accept reads of fixed length and produce files of impractical size.

% -----------------------------------------------------------------------------

\subsection{GEM}

The GEM mapper \citep{Gem} is a flexible read aligner for Illumina/Solexa, ABI/SOLiD, and Ion Torrent reads.
It is full-sensitive and can be configured either as an all-mapper, as a best/unique-mapper, or to search by strata.

GEM uses a combination of state of the art approximate string matching methods, \eg approximate seeds and suffix filters.
The program indexes the reference genome with an FM-index, tries to find an optimal filtration scheme per read, and verifies candidate locations using Myers algorithm.
Paired-reads are either mapped independently and then combined, or left/right are mapped and their mates verified using an online strategy.

Unfortunately the tool lacks direct SAM output, it is not open source, and provides many obscure parameters.

% -----------------------------------------------------------------------------

\subsection{Masai and Yara}

% -----------------------------------------------------------------------------

\begin{landscape}
\begin{table}[h]
  \center
  \sffamily
%  \resizebox{1.0\textwidth}{!}
%  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_mappers}
%  }
\end{table}
\end{landscape}

% =============================================================================

\chapter{Masai}

In this chapter we present our first attempt to engineer an efficient all-mapper.
When we started this project, in October 2011, the fastest all-mappers (mrFast and RazerS~3) were two order of magnitude slower than prominent best-mappers (Bowtie and BWA).
On one hand, all-mappers were using filtration based on exact seeds, which is fine for short reference genomes but becomes too weak for mammal genomes; clearly, a stronger filtration method would had been beneficial.
On the other hand, best-mappers were based on heuristic backtracking, which was becoming inadequate to map reads of increasing length.
After a thorough literature review, we came out with a novel read mapping method combining seed-based filtering with backtracking, that we published in \citep{Siragusa2013}.

In the engineering section, we see how our filtration method works, which data structures we adopt for indexing, and how we perform seed extension.
In particular, our filtration method is based on exact or approximate seeds: by employing approximate seeds instead of exact seeds, we obtain a stronger filter for long reference genomes, which is still non-heuristic and quasi full-sensitive.
We find approximate seeds by backtracking the index of the reference genome.
Moreover, we speed up the backtracking phase by searching all seeds simultaneously, with the help of an additional index and the multiple backtracking algorithm.
Lastly, we improve our method to perform best-mapping in a more efficient way.

Our method is packaged in a \CC tool nicknamed \emph{Masai}, which stands for \emph{m}ultiple backtracking of \emph{a}pproximate seeds on a \emph{s}uffix \emph{a}rray \emph{i}ndex.
Masai is part of the SeqAn library, it is distributed under the BSD license and can be downloaded from \url{http://www.seqan.de/projects/masai}.

In the evaluation section, we extensively compare Masai with popular read mappers, both on simulated and real datasets.
Compared to all-mappers mrFast and RazerS~3, Masai is an order of magnitude faster and has comparable sensitivity.
In addition, Masai as a best-mapper is 2--4 times faster and more accurate than Bowtie\,2 \citep{Bowtie2} and BWA \citep{BWA}.
Finally, we discuss the limitations of Masai that led us to engineer Yara, yet another read aligner.

% -----------------------------------------------------------------------------

\section{Engineering}

We start by giving an outline of the read mapping method of Masai.
Later, we give a detailed explanation of each mapping step, explaining and motivating relevant engineering choices that led us to the final implementation.

Masai requires an index capable of simulating a top-down traversal of the suffix trie of the reference genome.
We give to the user the possibility to choose among various indices (see section~\ref{masai:engineering:index}).
Similarly to all read mappers relying on an index of the reference genome, we index the reference genome only once, store it on disk and reuse it for all subsequent read mapping jobs.

At mapping time, Masai requires two parameters to be provided: a maximum number of errors per read and a minimum seed length.
Default parameters work well for actual Illumina reads, otherwise the user has to parametrize adequately the tool for optimal performance.
Nonetheless, independently of the chosen parameterization, filtration is guaranteed to be quasi full-sensitive (see section~\ref{masai:engineering:seeding}).

We partition all reads (and their reverse complements) in non-overlapping seeds;
subsequently we arrange all seeds in a conceptual \emph{trie}.
Using our \emph{multiple backtracking} algorithm, we backtrack simultaneously all indexed seeds in the suffix trie of the reference genome.
We perform seed extension on all hits reported by the multiple backtracking algorithm;
we extend both ends of each seed using a banded version of \emph{Myers bit-vector algorithm} \citep{Myers1999} (details in section~\ref{masai:engineering:extension}).

%In all-mapping, we perform one round of seeding and extension; we immediately write to disk each found mapping location.
%In best-mapping, we perform have to remember one best location per read until we are able to guarantee optimality.

\subsection{Filtration}
\label{masai:engineering:seeding}

%We now consider formally the read mapping problem.
%Given a reference genome $g$, a set of reads $\mathcal{R}$ and an absolute number of errors $k$ consisting of indels and mismatches, for each read $r \in \mathcal{R}$ find all mapping locations where $r$ approximately occurs in $g$ within $k$ errors.

Our original intent was to improve the speed of our all-mapper RazerS \citep{Weese2009} while preserving full-sensitivity under the edit distance.
RazerS was based on a $q$-gram filter;
we were aware that gapped $q$-grams could have brought a huge speedup, but we could not see any straightforward generalization of gapped $q$-grams to the edit distance.
At the same time, we experienced that weaker but quicker filtration using exact seeds was more advantageous than filtration using $q$-grams (indeed, a typical Illumina read mapping setup requires only moderate error rates, in the range of 4--6~\%).
Thus RazerS~3 \citep{RazerS3} went back to filtration with exact seeds (similarly to mrFast).
Nonetheless, we wanted to improve again filtration specificity, as the runtime of RazerS~3 on mammal genomes became dominated by verifications, and we knew that to improve filtration specificity we had to increase the seed length, as these two things are strongly correlated.

While reviewing past literature in the field of approximate string matching, we rediscovered the works of \citeauthor{Myers1994}, \citeauthor{Navarro2000} on approximate seeds, providing stronger filtration than exact seeds while preserving full-sensitivity under the edit distance.
Their idea is to partition the pattern into $s \leq k+1$ non-overlapping seeds, which obviously can be longer than exact seeds but have to be searched within distance $\lfloor k/s \rfloor$ (see section~\ref{filter:apx}).

Following \citep{Navarro2000}, we decided to find approximate seeds by backtracking the suffix trie of the reference genome (in section~\ref{masai:engineering:index} we recall our engineering work to find approximate seeds efficiently).
For simplicity, we decided to find approximate seeds only under the hamming distance.
For this reason, when resorting to approximate seeds, Masai does not attain strict full-sensitivity under the edit distance.
Nonetheless, in section~\ref{masai:evaluation} we show that such implementation detail sacrifices less than 1\% sensitivity.

Then, we slightly improved the filtration lemma of \citep{Navarro2000}:
we search $(k \bmod{s}) + 1$ seeds within distance $\lfloor k/s \rfloor$ and the remaining seeds within distance $\lfloor k/s \rfloor - 1$.
To prove full-sensitivity it suffices to see that, if none of the seeds occurs within its assigned distance, the total distance must be at least $s \cdot \lfloor k/s \rfloor + (k \bmod s) + 1 = k + 1$.
Hence all approximate occurrences will be found.

Finally, we chose to parameterize our filter by the seed length rather than by the number of seeds.
Clearly, these two parameterization are dual: if we choose the number of seeds to be $s$, the minimum seed length $l$ has to be $\lfloor |r|/s \rfloor$; vice versa, if we fix the minimum seed length to $l$, the number of seeds $s$ has to be $\lfloor |r|/l \rfloor$.
Nonetheless we prefer the latter, as the minimum seed length gives us a direct estimate of the expected number of verifications produced by the filter.
The resulting filter is flexible, indeed by increasing $l$ filtration becomes more specific at the expense of a higher filtration time.

The optimal seed length $l$ depends on the reference genome as well as on read length and the absolute number of errors.
We experimentally evaluated filtration with exact and approximate seeds (see section~\ref{masai:evaluation:filter}).
When mapping current Illumina reads on short to medium length genomes, exact seeds are still more efficient than approximate seeds.
Conversely, on larger genomes (\eg mammalian genomes) approximate seeds outperform exact seeds by an order of magnitude.

\subsubsection{Best-mapping}

In best-mapping, Masai reports the first encountered co-optimal mapping location per read.
Obviously, best-mapping makes sense if the scoring scheme adopted by the mapper is effective at identifying original mapping locations.
In section~\ref{masai:evaluation:rabema}, we see that best-mapping using edit distance is competitive with tools using more complex scoring schemes.

%Of course, we can perform all-mapping and then filter out any sub-optimal mapping location.
%Here we describe a method for best-mapping that, in standard scenarios, is an order of magnitude faster than all-mapping.

%I did not design Masai originally to perform best-mapping, only quickly adapted it to do the job.
%Masai does not produce mapping quality.
%In the next chapter, Yara.


\subsection{Indexing}
\label{masai:engineering:index}

Within the SeqAn library, we initially disposed of two indices capable of simulating a top-down suffix trie traversal: the enhanced suffix array (ESA) \citep{Abouelhoda2004} and the lazy suffix tree (LST) \citep{Giegerich1999}.
To improve the efficiency of Masai, we implemented a generic top-down traversal for some additional indices, namely the suffix array (SA) \citep{Manber1990}, the $q$-gram index, and various flavours of the full-text minute index (FM-index) \citep{Ferragina2001}.
Below we discuss the performance of these indices in our specific application, while we refer the reader to chapter~\ref{chr:index} for their extensive explanation.

\subsubsection{Indexing the reference genome}

We initially chose the ESA over LST because of better construction times.
Indeed, we dispose of a linear time construction algorithm for the ESA (an adaptation of the DC7 algorithm \citep{Dementiev2008} to multiple sequences \citep{Weese2013} for the generalized SA, followed by the algorithms proposed in \citep{Kasai2001,Abouelhoda2004}), while our LST construction algorithm takes quadratic time (using the radix sort based \emph{wotd}-algorithm \citep{Giegerich1999}).
Apart from that, both our ESA and LST implementations require $13$ bytes per base pair and exhibit comparable query speed.
Thus, for the human reference genome (GRCh38), we had a suffix trie constructed in about 1.5~hours and consuming 39~GB of memory (see figure~\ref{fig:index:construction}).

At this point, Masai required high-end hardware to process large reference genomes.
Therefore, thinking of a space-time trade-off, we designed a generic suffix trie top-down traversal for the SA (see section~\ref{sec:index:sa});
indeed, the SA consumes only $5$ bytes per base pair but is theoretically slower than the ESA, as it adds a logarithmic factor to query times.
However, with surprise we found out that, within our application, the SA had equal or better performance than the ESA (see figure~\ref{?}).
Ultimately, we brought down the memory footprint of the index from 39~GB to 15~GB but preserved query speed.

We tried to further improve query speed by removing the logarithmic factor introduced by the SA.
Therefore, to cut the most expensive binary searches, we put a $q$-gram index on top of the SA and extended our generic suffix trie top-down traversal accordingly (see section~\ref{sec:index:qgram}).
Yet, the $q$-gram index did not bring significant speedup to our application;
indeed, the lookup table turned out to be useful when searching patterns one by one, but not when coupled with our multiple backtracking algorithm as it performs a factorization of the top-down traversal.

Finally, we explored additional space-time trade-offs.
We started implementing\footnote{Thanks to the master's thesis of Jochen Singer.} a generalized FM-index based on a wavelet tree~\citep{Grossi2003}.
Our initial FM-index consumed about $1.5$ bytes per base pair with a SA sampling of 10~\%.
Thus the memory footprint of the index went down to 4.5~GB, but Masai became significantly slower (less than twice as slow though).

In definitive, we prefer the SA as it provides a good compromise between query speed and memory consumption.
Nevertheless, we leave to the user the possibility to choose among the aforementioned data structures.

\subsubsection{Indexing the reads}

In order to improve index query speed, we designed and implemented an algorithm to search simultaneously many exact or approximate seeds, achieving a speedup of 3--5 times (see section~\ref{sec:index:multi}).
As our multiple search algorithm requires a trie of the seeds, we also engineered an efficient trie implementation.

It was straightforward to reuse our suffix trie implementations to emulate tries.
It goes without saying that the easiest way to implement a trie is by means of a partial SA:
we index only the first suffix of each seed in the collection and construct the SA-based trie via quicksort in time $\Oh(n \log n)$, where $n$ is the number of seeds; then, our top-down traversal based on binary search still works.
We adapted the LST in an analogous way: we fill the partial SA as above and then apply the \emph{wotd}-algorithm \citep{Giegerich1999} to construct the trie in linear time.

Quicksorting the SA turned out to be faster than radix sorting the LST but, in our application, the more involved LST data structure payed off at query time (see section~\ref{sec:index:visit}).
Indeed, the LST stores all trie nodes and thus provides node traversal in constant time, while the SA explicitly stores only the leaves and thus internal nodes have to be worked out via binary search.
As the memory footprint of the trie is negligible within our application, we chose the LST to perform multiple backtracking of approximate seeds.

When performing multiple backtracking of exact seeds, the LST construction time dominates the overall filtration time (see section~\ref{sec:index:multi}).
Therefore, we decided to resort to the \emph{$q$-gram index} to emulate a trie in this case:
we build a partial $q$-gram index efficiently and in linear time by bucket sort, again considering only the first suffix of each seed in the collection.
Such index represents a trie truncated at depth $q$ (which we fixed to 12 in our application).
Truncation is only a minor concern: at depth $q$ we continue by applying the single backtracking algorithm on each active node.
%Given the sparseness of the seeds index, for exact search it pays off to adopt a trie based on a $q$-gram index rather than a LST-based trie.

\subsection{Verification}
\label{masai:engineering:extension}

To verify hits reported by the filtration algorithm, we use a banded version of Myers bit-vector algorithm \citep{Myers1999}.
Myers' algorithm is an efficient DP alignment algorithm \citep{Needleman1970} for edit distance. 
Instead of computing DP cells one after another, it encodes the whole DP column in two bit-vectors and computes the adjacent column in a constant number of 12 logical and 3 arithmetical operations.
We implemented a bit-parallel version that computes only a diagonal band of the DP matrix and is faster and more specific than the original algorithm by Myers.
More details can be found in section~\ref{asm:filter:verification}.

We had already used Myers' algorithm in RazerS~3~\citep{RazerS3}.
However, instead of performing a semi-global alignment to verify a parallelogram surrounding the seed, in Masai we perform a global alignment on both ends of a seed.
Given a seed occurring with $e$ errors, we first perform seed extension on the left side within an error threshold of $k - e$ errors.
Only if the seed extension on the left side succeeds, we perform a seed extension on the right side within the remaining error threshold.
Moreover, we first compute the longest common prefix on each side of the seed and let the global alignment algorithm start from the first mismatching positions.
We observed that this approach is up to two times faster than RazerS~3.

% -----------------------------------------------------------------------------

\section{Evaluation}

In order to evaluate Masai, we propose three experiments: \begin{inparaenum}[(i)]
\item the Rabema benchmark and
\item variant detection on simulated data, and
\item performance on real data.
\end{inparaenum}

It should be noted that in this evaluation we are interested on the capability of the mapper to retrieve the location of a single read without the help of read pairs, which can of course disambiguate mapping locations of the partner.

As references, we use whole genomes of E.~coli (NCBI NC\_000913.2), C.~elegans (WormBase WS195), D.~melanogaster (FlyBase release 5.42), and H.~sapiens (GRCh37.p2).

\subsection{Read mappers parametrization}

We compare Masai with the best-mappers Bowtie\,2, BWA and Soap\,2 as well as with the all-mappers RazerS\,3, Hobbes, mrFAST and SHRiMP\,2.
We remark that Bowtie\,2, BWA, Soap\,2 and SHRiMP\,2 rely on scoring schemes taking into account base quality values, while Masai, RazerS\,3, Hobbes and mrFAST use edit distance.
When relevant, we configured some read mappers with the appropriate absolute number of errors (Masai, mrFAST, Hobbes, Soap\,2) or error rate (RazerS\,3).
In the following, we give the exact parameterization for the read mappers considered in our evaluation.

\paragraph{Masai}
Version 0.5 was used.
In order to use Masai as an all-mapper, we passed the argument \texttt{--all}, otherwise the argument \texttt{--any-best} is used by default.
We set the maximal edit distance using the parameter \texttt{-e}.
We configured the seed length with the parameter \texttt{--seed-length}; on E.~coli, D.~melanogaster and C.~elegans we chose a seed length of $16$, while on H.~sapiens we chose a seed length of $33$.
We selected the SAM output format with \texttt{-os} and enabled CIGAR output with \texttt{-oc}.

\paragraph{Bowtie\,2}
Version 2.0.0-beta6 was used.
We used the parameter \texttt{--end-to-end} to enforce semi-global read alignments.
For the Rabema experiment we used the parameter \texttt{-k 100}.

\paragraph{BWA}
Version 0.6.1-r104 was used.
For the Rabema experiment we passed the parameter \texttt{-N} to \texttt{aln} and \texttt{-n 100} to \texttt{samse}.

\paragraph{Soap\,2}
Version 2.1 was used.

\paragraph{RazerS\,3}
Version 3.1 was used.
We mapped with indels using the pigeonhole filter (default) and set the error rate through the parameter \texttt{-i}, \eg \texttt{-i 95} to map within an error rate of 5\,\%.
We selected the native or SAM output format with \texttt{-of 0} or \texttt{-of 4}.

\paragraph{Hobbes}
Version 1.3 was used.
We built the index using the recommended $q$-gram length 11.
Since we focus on edit distance, we used the 16\,bit bit-vector version.
We enabled indels with \texttt{--indels} and set maximal edit distance using the parameter \texttt{-v}.
For resource measurement we used the output without CIGAR, for analyzing the results we enabled CIGAR output using \texttt{--cigar}.

\paragraph{mrFAST}
Version 2.1.0.6 was used.
We set maximal edit distance using the parameter \texttt{-e}.

\paragraph{SHRiMP\,2}
Version 2.2.2 was used.

\subsection{Rabema benchmark on simulated data}

We first consider the Rabema benchmark~\citep{Holtgrewe2011} (v1.1) for a thorough evaluation and comparison of read mapping sensitivity.
The benchmark contains the categories \emph{all}, \emph{all-best}, \emph{any-best}, \emph{precision}, and \emph{recall}.
In the categories all, all-best, and any-best a read mapper has to find all, all of the best, or any of the best edit distance locations for each read.
The categories precision and recall require a read mapper to find the \emph{original} location of each read, which is a measure independent of the used scoring model, \eg edit distance or quality based.
A read is mapped \emph{correctly} if the mapper reports its original location, 
and it is mapped \emph{uniquely} if the mapper reports only one location.
Rabema defines \emph{recall} to be the fraction of reads which were correctly mapped and \emph{precision} the fraction of uniquely mapped reads that were mapped correctly.

Similarly to \citep{Bowtie2}, we used the read simulator Mason \citep{SeqAnReadSimulator} with default profile settings to simulate from each whole genome 100\,k reads of length 100\,bp having sequencing errors distributed like in a typical Illumina run.
We performed the benchmark for an error rate of 5\,\%, which corresponds to edit distance 5 for reads of length 100\,bp. Therefore, we built a Rabema gold standard for each dataset by running RazerS~3 in full-sensitive mode up to edit distance 5. We further classified mapping locations in each category by their edit distance.

For a more fair and thorough comparison, we also consider BWA and Bowtie\,2 as all-mappers (Soap\,2 cannot be configured accordingly).
To this extent, we parametrized these tools to be highly sensitive and output all found mapping locations.
Since BWA and Bowtie\,2 were not designed to be used as all-mappers, they spent much more time than proper all-mappers, \ie up to 3~hours in a run compared to several minutes.
However, the aim of this experiment is to investigate read mapping sensitivity, therefore we do not report running times.
Results for H.~sapiens are shown in table~\ref{tab:Rabema}.

\subsubsection{Best-mappers}
Masai shows the best recall values, not loosing more than 3.3\,\% recall on edit distance 5.
Conversely, recall values of BWA and Bowtie\,2 drop significantly with increasing edit distance and loose up to 15.4\,\% and 11.5\,\% on edit distance 5.
As expected, Soap\,2 turns out to be inadequate for mapping reads of length 100\,bp at this error rates.

Precision values have less variance than recall values. Masai shows the best precision values with 97.8\,\%, followed by Soap\,2 with 97.7\,\%, and BWA with 97.5\,\%. Interestingly, Bowtie\,2 shows the worst precision values, loosing up to 5.6\,\% on edit distance 5.

\subsubsection{All-mappers}
As expected, RazerS\,3 shows full-sensitivity and mrFAST looses only a minimal percentage of mapping locations.
Overall, Masai does not loose more than 0.1\,\% of all mapping locations.
In particular, Masai is full-sensitive for low-error locations and looses only a small percentage of high-error locations, \ie its loss is limited to 0.1\,\% and 1.4\,\% of mapping locations at edit distance 4 and 5.

Conversely, BWA and Bowtie\,2 miss 35\,\% and 45\,\% of all mapping locations at edit distance 5 and their recall values as all-mappers do not substantially increase.
Likewise, SHRiMP\,2 is not able to enumerate all mapping locations, although its recall values are good.
Again, Hobbes has the worst performance.

We remark that Masai is not full-sensitive whenever approximate seeds are used, \eg on H.~sapiens. Indeed, Masai loses 0.1\,\% overall sensitivity in respect to RazerS\,3.
%Conversely, it attains full-sensitivity whenever exact seeds are used, \eg on E.~coli, C.~elegans and D.~melanogaster (Supplementary Data).
In general, RazerS\,3 should be used when full-sensitivity is required, \ie for read mappers benchmarking. However, our results show that Masai can replace RazerS\,3 or mrFAST as an all-mapper in practical setups.

\begin{table*}[t]
  \caption[Masai results in the Rabema benchmark]
  {
  \label{tab:Rabema}
    Rabema benchmark results on $100\,\text{k}\times 100\,\text{bp}$ Illumina-like reads.
    We show Rabema scores in percent (average fraction of edit distance locations reported per read).
    Large numbers show total scores in each Rabema category and small numbers show the category scores separately for reads with $\bigl(\begin{smallmatrix}\mbox{\tiny 0}&\mbox{\tiny 1}&\mbox{\tiny 2}\\\mbox{\tiny 3}&\mbox{\tiny 4}&\mbox{\tiny 5}\end{smallmatrix}\bigr)$ errors.
    }
  \vspace{-3mm}
  \center
  \sffamily
  \resizebox{0.95\textwidth}{!}
  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_masai_rabema}
  }
\end{table*}

\subsection{Variant detection on simulated data}

The second experiment analyzes the theoretical performance of Masai and other read mappers in genomic variation pipelines.
Similarly to \citep{Shrimp2}, we consider simulated reads containing sequencing errors, SNPs and indels, such that each read has an edit distance of at most 5 to its genomic origin.
Reads are grouped according to the number of contained SNPs and indels, where class $(s,i)$ consists of all reads with $s$ SNPs and $i$ indels.
We say that a read is mapped \emph{correctly} if a mapping location is reported within 10\,bp of its genomic origin;
it is considered to map \emph{uniquely} if only one location is reported by the mapper.
For each class we define \emph{recall} to be the fraction of reads which were correctly mapped and \emph{precision} the fraction of uniquely mapped reads that were mapped correctly.

We simulated 5 million Illumina-like reads of length $100$\,bp from the whole human genome using Mason.
We mapped the reads with each tool and measured its sensitivity in each class.
Table~\ref{tab:Variant} shows the results of each read mapper by class.

\subsubsection{Best-mappers}

Among best-mappers, Masai shows the highest precision and recall in all classes.
In particular, Masai does not loose more than 3.2\,\% recall in class (4,0), whether Bowtie\,2 and BWA loose respectively 17.5\,\% and 14.9\,\% and Soap\,2 is not able to map any read.

Interestingly, we observe that recall values of Bowtie\,2, BWA and Soap\,2 are negatively correlated with the amount of genomic variation.
For instance, in the Rabema benchmark, Bowtie\,2 looses respectively 7.2\,\% and 11.5\,\% of mapping locations at distance 4 and 5, but in class (4,0) of this experiment it looses 17.5\,\% recall.
We observe a similar trend for BWA and Soap\,2.
The low performance of Soap\,2 is also due to its limitation to at most 2 mismatches and no support for indels.

\subsubsection{All-mappers}

Looking at all-mappers results, Masai shows 100\,\% precision and recall in all classes, except for classes (2,0) and (1,1) where it looses only 0.1\,\% and 0.7\,\% recall.
Masai is therefore roughly comparable to the full-sensitive read mappers RazerS\,3 and mrFAST.
SHRiMP\,2 shows 100\,\% precision in all classes but looses between 0.3\,\% and 0.8\,\% recall in each class.
Hobbes has the lowest performance among all-mappers: it appears to have problems with indels, indeed it looses 9.5\,\% recall in class (0,3).

\begin{table*}[tH!]
  \caption[Masai variant detection results]
  {
  \label{tab:Variant}
    Variant detection results on $5\,\text{M}\times 100\,\text{bp}$ Illumina-like reads.
    We show the percentages of found origins (recall) and fraction of unique reads mapped to their origin (precision) classed by reads with $s$ SNPs and $i$ indels $(s,i)$.
  }
  \vspace{-3mm}
  \center
  \sffamily
  \resizebox{0.8\textwidth}{!}
  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_masai_variant}
  }
\end{table*}

\subsection{Performance on real data}

In the last experiment we focus on comparing read mappers performance on real data.
We mapped the first $10\,\text{M}\times 100\,\text{bp}$ reads from an Illumina lane of E.~coli (ERR022075, Genome Analyzer IIx), D.~melanogaster (SRR497711, HiSeq 2000), C.~elegans (SRR065390, Genome Analyzer II), and H.~sapiens (ERR012100, Genome Analyzer II).
Whenever possible we configured the tools to map the reads within edit distance 5.

We measured mapping times on a cluster of nodes with 72\,GB RAM and 2 Intel Xeon X5650 processors running Linux~3.2.0.
For an accurate running time comparison, we ran the tools using a single thread and used local disks for I/O.
We measured running times, peak memory consumptions, mapped reads and Rabema any-best scores.

We cannot measure precision and recall values as real reads have unknown origins.
Therefore, for this evaluation, we adopt the commonly used measure of percentage of \emph{mapped reads}, \ie the fraction of reads for which the read mapper reports a mapping location.
However, as some mappers report mapping locations without constraints on the number of errors, we also include Rabema \emph{any-best} scores.
We recall that the Rabema any-best benchmark assigns a point for a read if the mapper reports at least one mapping location with the optimal (minimum) number of errors;
final Rabema any-best scores are normalized by the number of reads.

Results for C.~elegans and H.~sapiens are shown in table~\ref{tab:Runtime}.
%Additional results for E.~coli, D.~melanogaster are shown in table.

\subsubsection{Best-mappers}
On the C.~elegans dataset, Masai is 7.7 times faster than Bowtie\,2, 8.2 times faster than BWA and 1.5 times faster than Soap\,2.
On the H.~sapiens dataset, Masai is 2.6 times faster than Bowtie\,2, 3.6 times faster than BWA but 2.1 times slower than Soap\,2.

On one end, Soap\,2 is not able to map a consistent fraction of reads because of its limitation to 2 mismatches.
On the other end, Bowtie\,2 reports more mapped reads than Masai but, taking any-best scores into account, it reports less mapping locations than Masai.
In fact, Bowtie\,2 uses a scoring scheme based on quality values and does not impose a maximal error rate threshold.
On the C.~elegans and H.~sapiens datasets, Bowtie\,2 misses respectively 22.0\,\% and 20.7\,\% of reads mappable at edit distance 5.

\subsubsection{All-mappers}
On the C.~elegans dataset Masai is 2.0 times faster than RazerS\,3, 10.9 times faster than Hobbes, 6.3 times faster than mrFAST and 50.1 times faster than SHRiMP\,2.
Hobbes constantly crashes and maps less reads than all other mappers in this category.

On the H.~sapiens dataset Masai is 11.9 times faster than RazerS\,3, 14.6 times faster than mrFAST, and 7.6 times faster than Hobbes.
We note that the current version of Hobbes constantly crashes and maps only half of the reads.
SHRiMP\,2 is not able to map the H.~sapiens dataset within 4 days.

Likewise for Bowtie\,2, also SHRiMP\,2 does not impose a maximal error rate threshold and reports more mapped reads than Masai.
However, its Rabema any-best score is inferior to Masai.
This could be due to the use of a different scoring scheme where two mismatches cost less than opening a gap.
Anyway, this hypothesis does not explain why SHRiMP\,2 does not report some mapping locations at distance 0.

\begin{table*}[t]
  \caption[Masai performance on real data]{
    \label{tab:Runtime}
    Performance on real data using $10\,\text{M}\times 100\,\text{bp}$ Illumina reads.\\
	Rabema any-best: in large we show the percentage of reads mapped with the minimal number of errors (up to 5\%) and in small the percentage of reads that were mapped with $\bigl(\begin{smallmatrix}\mbox{\tiny 0}&\mbox{\tiny 1\%}&\mbox{\tiny 2\%}\\\mbox{\tiny 3\%}&\mbox{\tiny 4\%}&\mbox{\tiny 5\%}\end{smallmatrix}\bigr)$ errors.\\
	Mapped reads: in large we show the percentage of mapped reads and in small the cumulative percentage of reads that were mapped with $\bigl(\begin{smallmatrix}\mbox{\tiny 0}&\mbox{\tiny 1\%}&\mbox{\tiny 2\%}\\\mbox{\tiny 3\%}&\mbox{\tiny 4\%}&\mbox{\tiny 5\%}\end{smallmatrix}\bigr)$ errors.\\
	Remarks:
    SHRiMP\,2 is not able to map the H.~sapiens dataset within 4 days;
    Hobbes constantly crashes and is not able to map completely nor the C.~elegans nor the H.~sapiens dataset.
  }
	\vspace{-3mm}
	\center
	\sffamily
	\resizebox{1.0\textwidth}{!}
	{
		\renewcommand{\tabcolsep}{0.8ex}
		\input{tables/table_masai_runtime}
	}
\end{table*}


\subsection{Filtration efficiency}

Here we assess the contribution of approximate seeds and multiple backtracking on runtime results.
To this intent we performed all-mapping with Masai on each previously considered dataset, this time using either exact or approximate seeds in combination with either single or multiple backtracking.
Table~\ref{tab:Filtration} shows the results.
Filtration time consists of the time spent to index the seeds (in case of multiple backtracking) and to perform backtracking.
Candidates reports the number of candidate locations reported by the filter for which seed extension is subsequently performed.
In bold we show the optimal combination of seeding and backtracking that we used to parameterize Masai.

Since we concentrate on filtration, we do not consider the time spent performing seed extensions and I/O, \ie loading the reference genome and its index, loading the reads, writing the results.
Such time is independent of any combination of seeding or backtracking and can be extrapolated by subtracting bold filtration times of table~\ref{tab:Filtration} from respective Masai all-mappers times of table~\ref{tab:Runtime} and table~\ref{?}.

On E.\,coli, D.\,melanogaster and C.\,elegans approximate seeds reduce the number of candidates respectively by 2.1 times, 9.9 times, and 4.3 times.
Nevertheless we still prefer exact seeds as filtration dominates the total runtime.
Multiple backtracking on exact seeds compared to single backtracking speeds up filtration by 2.9 times on E.\,coli, and 3.8 times on D.\,melanogaster and C.\,elegans.
Without the contribution of multiple backtracking Masai would not be faster than RazerS\,3, the second fastest all-mapper.

Approximate seeds become effective on H.\,sapiens, where they reduce the number of candidates by 10.8 times. 
On H.\,sapiens seed extensions largely dominate the total runtime, therefore we prefer approximate seeds.
Multiple backtracking on approximate seeds provides a speed-up of 3.2 times over single backtracking.
The combination of the two methods makes Masai an order of magnitude faster than any other all-mapper.

\begin{table*}[h]
  \center
  \caption[Masai filtration efficiency results]{
    \label{tab:Filtration}%
    Masai filtration efficiency results for all-mapping.
    Filtration time is given as [min:s] and includes seeds indexing time.
  }
  {
  \sffamily
  \footnotesize
  \begin{tabular}{llllrr}
    \toprule
	organism & dataset & seeding & backtracking & filtration time & candidates\\
    \midrule
E.\,coli & ERR022075 & exact & single & 3:55 & 69.17\,M\\
E.\,coli & ERR022075 & \textbf{exact} & \textbf{multiple} & \textbf{1:20} & \textbf{69.17\,M}\\
E.\,coli & ERR022075 & approximate & single & 38:42 & 33.08\,M\\
E.\,coli & ERR022075 & approximate & multiple & 9:00 & 33.08\,M\\
    \midrule
D.\,melanogaster & SRR497711 & exact & single & 8:15 & 1020.28\,M\\
D.\,melanogaster & SRR497711 & \textbf{exact} & \textbf{multiple} & \textbf{2:11} & \textbf{1020.28\,M}\\
D.\,melanogaster & SRR497711 & approximate & single & 100:18 & 102.78\,M\\
D.\,melanogaster & SRR497711 & approximate & multiple & 20:48 & 102.78\,M\\
    \midrule
C.\,elegans & SRR065390 & exact & single & 8:25 & 1065.70\,M\\
C.\,elegans & SRR065390 & \textbf{exact} & \textbf{multiple} & \textbf{2:11} & \textbf{1065.70\,M}\\
C.\,elegans & SRR065390 & approximate & single & 102:02 & 246.65\,M\\
C.\,elegans & SRR065390 & approximate & multiple & 21:33 & 246.65\,M\\
	\midrule
H.\,sapiens & ERR012100 & exact & single & 55:54 & 294943.86\,M\\
H.\,sapiens & ERR012100 & exact & multiple & 41:52 & 294943.86\,M\\
H.\,sapiens & ERR012100 & approximate & single & 165:45 & 27396.01\,M\\
H.\,sapiens & ERR012100 & \textbf{approximate} & \textbf{multiple} & \textbf{52:15} & \textbf{27396.01\,M}\\
    \bottomrule
  \end{tabular}
  }
  \vspace{2mm}
\end{table*}

\section{Discussion}

Masai consists of three important algorithmic methods: \begin{inparaenum}[(i)]
\item approximate seeds,
\item multiple backtracking and
\item greedy filtration.
\end{inparaenum}
Approximate seeds are of paramount importance to obtain very specific yet full-sensitive filtration; their adoption speeds up Masai by one order of magnitude.
Multiple backtracking further speeds up the filtration phase by 3--5 times on a (enhanced) suffix array index; this technique makes Masai twice as fast.
Greedy filtration prioritizes analysis of optimal mapping locations; because of this method, Masai in best-mapping is an order of magnitude faster than in all-mapping.

Is the edit distance sufficient to perform best-mapping?
Both Rabema benchmark and variant detection results show that Masai has constantly better accuracy than other best-mappers relying on more complex scoring schemes.
In particular, the Rabema benchmark results show that Rabema any-best values are tightly bound to recall values.
Hence, the edit distance is a pertinent and adequate scoring scheme for best-mapping.
Vice versa, best-mappers using scoring schemes based on quality values show a generalized and substantial loss of mapping accuracy.
This is likely due to the heuristics on which these tools rely.
To sum up, it is better to stick to edit distance and guarantee full-sensitivity rather than to adopt an involved scoring scheme and explore the alignment space heuristically, hence partially.

How many mapping locations do heuristic best-mappers miss?
By looking at precision and recall values on simulated data, or at Rabema any-best values on real data, it can be deduced that Bowtie\,2, BWA and Soap\,2 miss up to 20\,\% of reads mappable at 5\,\% error rate.
Yet, it is not evident how these results affects variant calling pipelines.

Summing up, Masai as an all-mapper is an order of magnitude faster and thus a valid alternative to tools like RazerS~3 and mrFast.
Computational requirements of all-mapping now become close to those of best-mapping: Masai as an all-mapper is only 4 times slower than BWA, despite reporting two orders of magnitude more mapping locations.
Masai as a best-mapper is 2--4 times faster and more accurate than Bowtie\,2 \citep{Bowtie2} and BWA \citep{BWA}.
The achieved speedup is huge when RazerS~3 has to be used as a best-mapper: in this scenario, Masai is roughly 200 times faster!

Despite the good results, Masai is not being widely used.
This is mainly because it lacks some commonly requested features, including:
parallelization via multi-threading, low memory footprint, direct support of paired-end or mate-pair protocols, computation of mapping qualities, automatic parameterization.
Because of initial inexperience and unclear (or wrong) goals, I neglected these requirements while designing the tool.
The next chapter introduces \emph{Yara}, \emph{y}et \emph{a}nother \emph{r}ead \emph{a}ligner, a tool fulfilling these requirements.


% =============================================================================

\chapter{Yara}

\emph{Yara} (\emph{Y}et \emph{a}nother \emph{r}ead \emph{a}ligner) is an exhaustive, non-heuristic read mapper, capable of quickly reporting all stratified mapping locations within a given error rate.
Yara offers parallelization via multi-threading, has a low memory footprint by using the FM-index, directly supports paired-end or mate-pair protocols, computes accurate mapping qualities, does not require ad-hoc parameterization and works on Illumina or Ion Torrent reads.

% -----------------------------------------------------------------------------

\section{Engineering}

\subsection{Ad-hoc filtration}

Specific yet rapid filtration is fundamental in the design of an efficient read mapping tool.
Read mappers like RazerS\,3 \citep{RazerS3} and mrFast \citep{Ahmadi2011} are designed around na\"ive filtration with exact seeds.
This filtration method is always very quick, however it is not specific enough on long, repetitive reference genomes like the human genome.
Masai \citep{Siragusa2013} circumvents this problem by enforcing a minimum seed length,
whose optimal value must be tuned for a specific reference genome, and eventually resorting to approximate seeds in order to guarantee full-sensitivity.
This filtration method speeds up Masai by an order of magnitude but is still rough:
it needs external parametrization, lacks flexibility and is suboptimal in practice.

Yara applies an ad-hoc filtration scheme \emph{per read}.
Under any fixed filtration scheme, the number of verifications per read is not uniform: within a typical mapping, most reads produce very few verifications and are easily mappable, while a few others are problematic and often not even confidently mappable to one single location.
Consequently, any fixed filtration scheme turns out to be too weak for some reads yet too strong for others, thus suboptimal in practice.
An ad-hoc filtration scheme per read improves filtration efficiency by optimizing the ratio between filtration speed and specificity.
Yara thus automatically chooses an ad-hoc filtration scheme per read, without requiring manual parameterization by the user.

Ad-hoc filtration works as follows.
Yara initially applies filtration with exact seeds to all reads.
The tool counts the number of verifications to be performed for each read, thus decides if it is worth proceeding with the verification phase or alternatively applying a stronger filtration scheme.
This decision depends on fine-tuned internal verification thresholds.
Under standard Illumina setups, exact seeds provide efficient filtration for up to 70--80\,\% of the reads; on the remaining reads, a filtration scheme using $1$-- or $2$--approximate seeds works better.
Thus, Yara starts with the quickest filtration scheme and becomes more specific whenever it pays off to do so.

%For instance, when mapping 100\,bp Illumina reads on the human genome within 5\,\% error rate, filtration with exact seeds produces 6 exact seeds of length 16\,bp;
%under these terms, a single read produces an average of 15000 verifications, and the verification phase takes 99\,\% of the runtime.
%On the same mapping setup, this method produces 3 $1$--approximate seeds of length 33\,bp; thus a single read produces 1400 verifications on average.
%Under this setup, Masai in all-mapping still spends about 20\,\% of its runtime in filtration and the remaining 80\,\% in verification.
%The next stronger filter produces 2 $2$--approximate seeds of length 50\,bp.

\subsection{Stratified filtration}

All-mapping methods consider a set of relevant mapping locations per read.
Yet, this definition leaves open what relevant means.
In all-mapping under the edit distance, the user defines relevant mapping locations by imposing a distance threshold.
Despite being sound, this definition does not work well in practice.
On the one hand a very low threshold leaves a consistent fraction of the reads unmapped, on the other hand a moderate threshold produces a deluge of mapping locations for some reads.
In practice, at 5\,\%, error rate, Illumina reads map to hundreds of mapping locations on the human genome.
It is questionable whether all these locations are relevant for the downstream analysis.
Thus, a finer definition of all-mapping relevance is necessary in practice.

Stratification of mapping locations yields an equally sound yet practical definition of all-mapping under the edit distance.
The $e$-stratum
\begin{eqnarray}
S(r,e) = \{ (i,j,e) : d_E(g_{i,j},r) = e\}
\end{eqnarray}
denotes the set of all mapping locations of a read $r$ at edit distance $e$ from the reference genome $g$.
According to the above definition, conventional all-mapping under the edit distance defines the set
\begin{eqnarray}
S(r,0) \cup S(r,1) \cup \dots \cup S(r,k)
\end{eqnarray}
as relevant mapping locations within error threshold $k$.
Stratified all-mapping refines this definition by considering only mapping locations being co-optimal, or sub-optimal up to a certain degree.
Formally, if the distance of any optimal mapping location for read $r$ is
\begin{eqnarray}
e^* = \min_{b \in [0,k]}{S(r,b) \neq \emptyset}
\end{eqnarray}
stratified all-mapping considers mapping locations
\begin{eqnarray}
S(r,e^*) \cup \dots \cup S(r,\min{e^*+s, k})
\end{eqnarray}
within a fixed sub-optimality threshold $s$ to be relevant.

Stratified all-mapping could be implemented as a simple post-processing of the mapping locations found by conventional all-mapping.
For instance, RazerS\,3 implements this method.
Still, seed-based filtration can be generalized to consider only relevant strata, in order to reduce the search space analyzed, depending on the specified sub-optimality threshold.
One na\"ive solution consists into applying conventional all-mapping from 0\,\% error rate to the maximum error rate.
Yet, if a read maps at maximum distance, the work done to map it is much higher.
Stratified filtration instead guarantees not to perform more work than conventional filtration.


%Greedy strategy: sort the seeds by number of hits.
%Minimizes the number of verifications to perform in order to find the set of relevant mapping locations.


Stratified filtration is useful also in best-mapping.
In best-mapping the goal is to report one best mapping location along with its confidence.
Yara reports as primary one random co-optimal mapping location under the edit distance, along with its mapping quality.
% Yara uses the best strata
%(i) to compute precise mapping qualities
%(ii) to perform paired-end mapping.


\subsection{Paired-end and mate-pair protocols}

Paired-end and mate-pair protocols are the sequencing protocols of choice of Illumina instruments.
Reads are sequenced in pairs from both ends of the same insert.
Properly paired reads are expected to map within the insert size adopted in the sequencing protocol.
The lack of any proper pair of mapping locations signals a potential structural variation, \eg a long indel or an inversion.
Thus, the added information of an expected insert size allows a read mapper to map read pairs to their original locations more confidently than in the single-end protocol.
Nonetheless, a read mapper should report equally important unpaired mapping locations.

In the paired-end or mate-pair workflows, Yara maps paired reads independently, exactly as in the single-end workflow, and reports all relevant mapping locations per read.
However, in addition to the single-end workflow, Yara implements a finer strategy to choose primary mapping locations.
For any reads pair, among all pairs of co-optimal mapping locations, the tool selects the one with minimal deviation from the expected insert size.
Since Yara outputs all relevant mapping locations, the choice of primary locations can be always corrected a posteriori.

\subsection{Mapping qualities}

Yara computes mapping qualities using the number of mapping locations stratified by error rate.
%Mapping quality for the paired-end and mate-pair protocols.

\subsection{Indexing}

I engineered an efficient FM-index for the DNA alphabet.

\subsection{Parallelization}

I dropped multiple backtracking and implemented fine-grained parallelism.

%fine-grained parallelism by read level down to seeds.

% -----------------------------------------------------------------------------

\section{Evaluation}

The evaluation consists of three experiments: \begin{inparaenum}[(i)]
\item accuracy on simulated data,
\item Rabema benchmark on simulated and real data, and
\item throughput on real data.
\end{inparaenum}
In each experiment, I compare Yara in best-mapping with GEM, Bowtie\,2 and BWA, while in all-mapping with GEM, RazerS\,3, and Hobbes\,2.

\subsection{Experimental setup}

\subsubsection{Read mappers parametrization}

In the following, I give the exact parameterization of each read mapper considered in the evaluation.
Whenever possible, I configured the tools with the appropriate error rate (Yara, GEM, RazerS\,3) or absolute number of errors (Hobbes\,2).
When processing paired-end reads, I provided the tools with appropriate insert size information.
Below, \texttt{MIN} and \texttt{MAX} are placeholders for minimal and maximal insert size, while \texttt{INS} is the mean insert size and \texttt{ERR} its allowed deviation, \ie \texttt{INS = (MIN + MAX) / 2}, \texttt{ERR = (MAX - MIN) / 2}.

\paragraph{Yara}
Version 1.0 was used.
To perform all-mapping, we passed the argument \texttt{--all}; by default, the tool runs as a best-mapper.
We set the error rate using the parameter \texttt{-e}.
In paired-end mode, the parameters used were \texttt{--library-length INS --library-error ERR}.
The number of threads was set with the parameter \texttt{-t}.

\paragraph{GEM}
Version 1.376 was used.
We set the error rate using the parameters \texttt{-m} and \texttt{-e}, then we disabled adaptive mapping using the parameter \texttt{--quality-format ignore}.
In best-mapping, to analyze only the best stratum, we passed the argument \texttt{-s 0};
in all-mapping, to analyze all strata, we passed \texttt{-d all -D all -s all --max-big-indel-length 0}.
In single-end mode, we passed the parameter \texttt{--expect-single-end-reads}; in paired-end mode, we passed \texttt{--paired-end-alignment}, along with \texttt{--min-insert-size MIN --max-insert-size MAX}, and \texttt{--map-both-ends} to select the workflow mapping both reads independently.
The number of threads was selected using the parameter \texttt{-t}.

\paragraph{Bowtie\,2}
Version 2.2.1 was used.
We used the parameter \texttt{--end-to-end} to enforce semi-global read alignments.
%For the Rabema benchmark we used the parameter \texttt{-k 100}.
In paired-end mode, we used the parameters \texttt{--minins MIN --maxins MAX}.
The number of threads was selected using the parameter \texttt{-p}.

\paragraph{BWA}
Version 0.7.7-r441 was used.
%For the Rabema experiment we passed the parameter \texttt{-N} to \texttt{aln} and \texttt{-n 100} to \texttt{samse}.
We used the parameter \texttt{-t} to select the number of threads in the \texttt{aln} step;
the \texttt{sampe} and \texttt{samse} steps were performed using one thread since BWA does not offer any parallelization here.

\paragraph{Hobbes\,2}
Version 2.1 was used.
We built the index using the recommended $q$-gram length 11.
We enabled edit distance with \texttt{--indels} and set the distance threshold using the parameter \texttt{-v}.
In paired-end mode, we used the parameters \texttt{--pe --min MIN --max MAX}.
Multi-threading was enabled using \texttt{-p}.

\paragraph{RazerS\,3}
Version 3.2 was used.
We set the error rate through the parameter \texttt{-i}, \eg \texttt{-i 95} to map within an error rate of 5\,\%.
We passed the option \texttt{-rr 100} to set the recognition rate to 100\,\% and \texttt{-m 1000000} to output all mapping locations per read.
In paired-end mode, the parameters used were \texttt{--library-length INS --library-error ERR}.
The number of threads was set with the \texttt{-tc} parameter.

\subsubsection{Infrastructure}

All tools run on a desktop computer running Linux~3.10.11, equipped with one Intel Core i7-4770K CPU @ 3.50\,GHz, 32\,GB RAM and a 2\,TB HDD @ 7200\,RPM.
For maximum throughput, all tools run using eight threads.
For accurate running time comparisons, I disabled Intel Turbo Boost; therefore, real throughputs might be slightly lower than the measured ones.

\subsubsection{Datasets}

The reference in all experiments is the human whole genome (GRCh38).

The simulated data consists of $1\,\text{M}$ Illumina-like $2 \times 100\,\text{bp}$ paired-end reads, simulated from the reference genome using Mason \citep{SeqAnReadSimulator}.
The mean insert size is \texttt{INS = 175} and the deviation \texttt{ERR = 225}.

The real data is a publicly released sequencing run (SRA/ENA id: ERR161544) by the Beijing Genome Institute;
the genomic DNA used in this study came from an anonymous male Han Chinese individual who has no known genetic diseases.
This dataset consists of $2 \times 100\,\text{bp}$ whole genome sequencing reads, produced by an Illumina HiSeq 2000 instrument.
BWA reports mean insert size \texttt{INS = 178} and deviation \texttt{ERR = 200}.

\subsection{Accuracy on simulated data}

I introduce an \emph{accuracy benchmark} to measure read mappers accuracy of finding the \emph{original} location of simulated reads.
This benchmark considers for each read only the \emph{first primary mapping location} encountered while scanning the SAM file \citep{?} produced by each tool;
this policy mimics the behavior of de-facto standard \emph{best-mapping analysis pipelines}, \eg the GATK \citep{DePristo2011}.
This accuracy benchmark counts a simulated read as \emph{correctly mapped} if the found mapping location corresponds to its original location,
it computes the \emph{recall} of each tool as the fraction of correctly mapped reads and the \emph{precision} as the fraction of mapped reads that are correct;
for a thorough evaluation, it also classes all simulated reads by the \emph{error rate} of their original locations, then computes recall and precision within each error rate class.

I repeated this experiment twice: first providing the simulated reads as unpaired, then as paired-end with additional insert size information.
Results are shown in table~\ref{tab:yara:accuracy}.

%This experiment is independent of the scoring scheme used by any tool, \eg edit distance or quality based.
%It does not consider mapping qualities; a mapping quality cutoff tends to lower recall and increase precision of all tools.

%\subsubsection{Single-end mapping}
%Comment best and all-mappers. All-mappers do not perform better than best-mappers as we consider only one primary mapping location.
%\subsubsection{Paired-end mapping}
%Comment the accuracy improvement due to paired-end information.

\begin{table*}[t]
  \caption[Yara accuracy results]
  {
  \label{tab:yara:accuracy}
    Accuracy results on the human whole genome.
    The left panel shows the results of mapping $1\,\text{M}$ Illumina-like $2 \times 100\,\text{bp}$ reads as unpaired; the right panel shows the results of mapping the same reads as paired-end, providing additional insert size information.
    Big numbers show total scores, while small numbers show marginal scores for the reads at $\bigl(\begin{smallmatrix}\mbox{\tiny 0}&\mbox{\tiny 1}&\mbox{\tiny 2}\\\mbox{\tiny 3}&\mbox{\tiny 4}&\mbox{\tiny 5}\end{smallmatrix}\bigr)$ \% error rate.
    }
  \vspace{-3mm}
  \center
  \sffamily
  \resizebox{0.95\textwidth}{!}
  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_yara_accuracy}
  }
\end{table*}


\subsection{Rabema benchmark on simulated and real data}

The \emph{Rabema benchmark} \citep{Holtgrewe2011} (v1.1) measures read mappers sensitivity of finding \emph{relevant} mapping locations of simulated or real reads.
This experiment considers the Rabema benchmark category \emph{all} for all-mappers and \emph{all-best} for best-mappers.
In the category all, Rabema counts as relevant, for each read, all mapping locations within a maximal error rate; in the category all-best it considers just co-optimal mapping locations.
Rabema computes the \emph{sensitivity} of each tool as the fraction of relevant mapping locations found per read.
Analogously to the accuracy benchmark, Rabema classes mapping locations by their \emph{error rate}, then computes sensitivity within each error rate class.
The benchmark reports percentual scores normalized by the number of reads.

I applied the Rabema benchmark both on simulated and real data, within an error rate of 5\,\%.
Therefore, I built a Rabema gold standard for each dataset by running RazerS\,3 in full-sensitive mode up to 5\,\% error rate.
I provided unpaired reads to each tool as the Rabema benchmark by definition does not consider paired-end reads.
Results are shown in table~\ref{tab:yara:rabema}.

%Contrarily to the accuracy experiment of section~\label{sec:yara:evaluation:accuracy}, this experiment considers multiple mapping locations per read.

%\subsubsection{Simulated data}
%\subsubsection{Real data}

\begin{table*}[t]
  \caption[Yara results in the Rabema benchmark]
  {
  \label{tab:yara:rabema}
    Rabema benchmark results on the human whole genome.
    The left panel shows the results of mapping $1\,\text{M}$ Illumina-like $2 \times 100\,\text{bp}$ simulated reads; the right panel shows the results of mapping $1\,\text{M}$ Illumina $2 \times 100\,\text{bp}$ real reads.
%    Big numbers show total scores in each Rabema category and small numbers show the category scores separately for reads with
    Big numbers show total Rabema scores, while small numbers show marginal scores for the mapping locations at
    $\bigl(\begin{smallmatrix}\mbox{\tiny 0}&\mbox{\tiny 1}&\mbox{\tiny 2}\\\mbox{\tiny 3}&\mbox{\tiny 4}&\mbox{\tiny 5}\end{smallmatrix}\bigr)$ \% error rate.
    }
  \vspace{-3mm}
  \center
  \sffamily
  \resizebox{0.95\textwidth}{!}
  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_yara_rabema}
  }
\end{table*}


\subsection{Throughput on real data}

This experiment complements the sensitivity evaluation on real data provided by the Rabema benchmark.
The goal of this experiment is to determine if read mappers are able to sustain sequencing throughput of the instrument or constitute a potential bottleneck in the data analysis pipeline.
The Illumina HiSeq\,2500 in a six days run produces\footnote{According to the specifications at \url{http://res.illumina.com/documents/products/datasheets/datasheet_hiseq2500.pdf} for high output run mode with dual flow cell.} up to 800~Gbp as $2 \times 100\,\text{bp}$ paired-end reads.
The experiment measures read mapping throughput in \emph{giga base pairs per hour} (Gbp/h); under this measure the maximum throughput of the Illumina HiSeq\,2500 is $5.56$ Gbp/h.

For an accurate throughput estimation, best-mappers processed $10\,\text{M}$ Illumina $2 \times 100\,\text{bp}$ reads, while for all-mappers it was sufficient to process $1\,\text{M}$ reads.
For a fair comparison, best-mappers produced a SAM file as expected by de-facto standard best-mapping pipelines, while all-mappers output a file in native format (SAM for Yara and Hobbes\,2, custom for Gem and RazerS\,3).

%\subsubsection{Single-end mapping}
%\subsubsection{Paired-end mapping}

\begin{table*}[t]
  \caption[Yara throughput on real data]
  {
    \label{tab:yara:throughput}
    Read mapping throughput on the human whole genome.
    All tools run using 8 threads on a desktop computer equipped with an Intel Core i7-4770K CPU.
    The left panel shows the results of mapping $2 \times 100\,\text{bp}$ Illumina HiSeq\,2000 reads as single-end;
    the right panel shows the results of mapping the same reads as paired-end.
    The maximum throughput of an Illumina HiSeq\,2500 is $5.56$ Gbp/h.
  }
	\vspace{-3mm}
	\center
	\sffamily
%	\resizebox{1.0\textwidth}{!}
%	{
		\renewcommand{\tabcolsep}{0.8ex}
		\input{tables/table_yara_throughput}
%	}
\end{table*}

%\subsection{Variant calling on real data}
%This experiments assesses the performance of read mappers on variant calling using real data.
%I use the GCAT benchmark.

% -----------------------------------------------------------------------------

%\section{Discussion}

%Yara does not consider local alignments and chimeric reads.

\chapter{Read Mapping}

Next generation sequencing is a terrific technology.
A wealth of applications have been developed on top of it.
Data analysis pipelines for variant calling and structural variation discovery from DNA-seq, mRNA transcripts abundance estimation and novel non-coding RNA discovery from RNA-seq, transcription factor binding-sites prediction from ChIP-seq.
All these applications rely on a common prerequisite step: mapping NGS reads to a known reference genome.

Read mapping is a critical step in all NGS data analysis pipelines.
NGS reads produced by all current technologies contain sequencing errors, in form of single miscalled bases or stretches of oligonucleotides.
Moreover, the donor genome from which reads have been sequenced contains small genomic variations (SNVs, Indels) in addition to CNV, inversions and translocations.
After all, spotting genomic variation is one reason for which we resequence genomes.
Thus, when mapping a read to a reference genome, it is not sufficient to consider the loci where the reads map exactly; it is necessary to consider any loci of relevant sequence similarity, being possible origins of the sequenced reads.

\section{Sequencing technologies}
\subsection{Illumina}
\subsection{Ion Torrent}

\section{Genome mappability}

Genome mappability has been recently studied by \citep{Derrien2011}, \citep{Lee2012}.
We start by giving our generic definition of genome mappability, analogous to \citep{Derrien2011}.

\subsection{Definitions}

\subsubsection{Mappability}

We extract a perfect read (without sequencing errors) from a reference genome, we map it back within a given distance, we count to how many loci it maps back.
Mappability at position $i$, denote by the function $M(i)$, is the inverse mapping frequency.
Any location $i$ for which $M(i) < 1$ is not unambiguously mappable.

\subsubsection{Pileup mappability}

If we focus our attention to the resequencing accuracy at a single locus, we have to consider the mappability of all the possible reads spanning that given locus.
Pileup mappability \citep{Derren2011} at position $i$ is the average mappability of all reads spanning position $i$.

$M_p(i) = 1/q \sum_{j=i}^{i+1}{M(j)}$

\citep{Lee2011} genome mappability score (GMS) is analogous to pileup mappability.
They start by considering the mappability at position $i$ as the probability that the read ending at position $i$ can be mapped correctly.
This probability is the mapping quality.
Then, they define the $GMS(i)$ as the average probability that all reads spanning position $i$ can be mapped correctly.

\begin{center}
\input{tables/table_gms}
\end{center}

\subsubsection{Paired-end mappability}

TODO.

\subsection{Genome mappability of model organisms}

Genome mappability can bias NGS analysis more than we might think at a first glance.
By considering a reference genome of length $n$, randomly generated under the uniform bernoulli model, we would expect any string of length $log_4(n)$ to occur about once.
In the human genome almost all 17-mers would be unique, on fly 15-mers, on worm 13-mers.

Sticking to these assumptions, we would expect 36~bp reads produced by early Illumina sequencers to induce an almost perfect mappability. For two reasons, this is not the case:
\begin{itemize}
\item the $k$-mers distribution of model genomes does not fit the uniform bernoulli distribution.
In \cite{?} the $k$-mers distribution can be approximated by a double Pareto log-normal distribution, \ie a distribution with a heavy tail.
This is a result of the evolution of genomes being driven by gene duplications, retrotransposons \cite{?}

\item Reads have to be mapped approximately to the reference genome.
The expected number of approximate occurrences of a $k$-mer is higher than the exact one.
Thus the above estimate is a lower bound.
\end{itemize}

\subsection{The Uniqueome}

\citep{Derren2011} quantified the whole genome unique mappability for human, mouse, fly, and worm.
At a $(36,2)$ mapping, about 30~\% of the human genome is not uniquely mappable.
Unique mappability rises to 83~\% by increasing the read length to 75~bp; however to map a significant fraction of the reads, we should consider 3--4 edit distance errors.

\begin{center}
\input{tables/table_mappability}
\end{center}

The uniqueome plays an important role in ChIP-seq experiments.
It is common practice \cite{?} to rely on short (36~bp) reads and discard the non-unique ones.
Not only a significant fraction of the sequencing data is thrown out.
Worse than that, we end up with holes in 30~\% of the genome.
A ChIP-seq peak caller considering multi-reads calls up to 30~\% more peaks.

Cite regions of clinical relevance, \eg HLA-A.
Cite regions of biological relevance, \eg 5S rRNA.


\section{Read mappers}

\subsection{Best mappers versus all mappers}

The task of a read mapper is to guess where a read originates.
Fixed a similarity scoring scheme that confidently models this problem, the optimal alignment under this scoring scheme correspond to the most likely explanation and induces a locus being the origin of the read.
The simplest scoring scheme is the edit distance; more involved scoring schemes take into account base quality values, score gaps using affine cost functions, or allow to trim for free a prefix or a suffix of the read.

The above definition does not consider two problems: what if there are many co-optimal candidates, and what if the correct solution corresponds to a sub-optimal candidate.
The former problem is exacerbated by genome mappability.
One would expect such situations to arise very rarely, but instead it is a relevant problem.
The latter problem arises whenever our model is not adequate to explain the difference between a read and its genomic origin.
For instance, an evolutionary event producing an indel of length $l$ might be considered as a unit, whether edit distance would consider it as $l$ independent events.
Under the edit distance, an alignment with less than $l$ independent point mutations would be considered more likely than an alignment containing only one indel of length $l$.

From the former problem, we conclude that considering only one optimal mapping location is not sufficient, no matter how good our scoring scheme can be.
The latter problem tells us to be careful about relying on strict optimality.
Therefore, in general a read mapper should return a comprehensive set of relevant mapping locations along with the likelihood that they correspond to the original location.

\subsection{Popular read mappers}

Cite tens of surveys classifying hundreds of mappers.
Critic the surveys.
Critic the mappers.

\begin{table}[h]
  \center
  \sffamily
  \resizebox{1.0\textwidth}{!}
  {
	\renewcommand{\tabcolsep}{0.8ex}
	\input{tables/table_mappers}
  }
\end{table}

\subsubsection{Bowtie}

\subsubsection{BWA}

\subsubsection{Soap}

\subsubsection{RazerS}

\subsubsection{mrFast}

\subsubsection{SHRiMP}

\subsubsection{GEM}

\section{Masai}
\subsection{Single-end mapping}
\subsection{Paired-end mapping}
\subsection{Parallelization}
\subsection{Hardware acceleration}

\section{Assessment of read mappers performance}
\subsection{Comparison of filtration strategies}
\subsection{Rabema benchmark results}
\subsection{Variant detection results}
\subsection{Runtime results}
\section{Discussion}